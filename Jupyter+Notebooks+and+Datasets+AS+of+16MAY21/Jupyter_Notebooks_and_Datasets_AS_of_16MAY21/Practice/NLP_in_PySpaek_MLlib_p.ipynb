{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are working with 1 core(s)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://localhost:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.3.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>NLP</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7ffb1b594cd0>"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.appName(\"NLP\").getOrCreate()\n",
    "cores = spark._jsc.sc().getExecutorMemoryStatus().keySet().size()\n",
    "print(\"You are working with\", cores, \"core(s)\")\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import *\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.ml.classification import *\n",
    "from pyspark.ml.evaluation import *\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "\n",
    "# For pipeline development\n",
    "from pyspark.ml import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/home/randi/Documents/pyspark_udemy/Jupyter+Notebooks+and+Datasets+AS+of+16MAY21/Jupyter_Notebooks_and_Datasets_AS_of_16MAY21/Practice/Datasets/\"\n",
    "\n",
    "df=spark.read.csv(path+'kickstarter.csv', inferSchema=True, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/25 10:14:22 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , blurb, state\n",
      " Schema: _c0, blurb, state\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/randi/Documents/pyspark_udemy/Jupyter+Notebooks+and+Datasets+AS+of+16MAY21/Jupyter_Notebooks_and_Datasets_AS_of_16MAY21/Practice/Datasets/kickstarter.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_c0</th>\n",
       "      <th>blurb</th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Using their own character, users go on educati...</td>\n",
       "      <td>failed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>MicroFly is a quadcopter packed with WiFi, 6 s...</td>\n",
       "      <td>successful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>A small indie press, run as a collective for a...</td>\n",
       "      <td>failed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Zylor is a new baby cosplayer! Back this kicks...</td>\n",
       "      <td>failed</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  _c0                                              blurb       state\n",
       "0   1  Using their own character, users go on educati...      failed\n",
       "1   2  MicroFly is a quadcopter packed with WiFi, 6 s...  successful\n",
       "2   3  A small indie press, run as a collective for a...      failed\n",
       "3   4  Zylor is a new baby cosplayer! Back this kicks...      failed"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.limit(4).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/25 10:14:22 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , blurb, state\n",
      " Schema: _c0, blurb, state\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/randi/Documents/pyspark_udemy/Jupyter+Notebooks+and+Datasets+AS+of+16MAY21/Jupyter_Notebooks_and_Datasets_AS_of_16MAY21/Practice/Datasets/kickstarter.csv\n",
      "+---+-----------------------------------------------------------------------------------------------------------------------------------+----------+\n",
      "|_c0|blurb                                                                                                                              |state     |\n",
      "+---+-----------------------------------------------------------------------------------------------------------------------------------+----------+\n",
      "|1  |Using their own character, users go on educational quests around a virtual world leveling up subject-oriented skills (ie Physics). |failed    |\n",
      "|2  |MicroFly is a quadcopter packed with WiFi, 6 sensors, and 3 processors for ultimate stability -- and fits in the palm of your hand.|successful|\n",
      "|3  |A small indie press, run as a collective for authors who want to self-publish, and a sexy, smart , hilarious novel!                |failed    |\n",
      "|4  |Zylor is a new baby cosplayer! Back this kickstarter to help fund new cosplay photoshoots to share his cuteness with the world!    |failed    |\n",
      "+---+-----------------------------------------------------------------------------------------------------------------------------------+----------+\n",
      "only showing top 4 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(4, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _c0: string (nullable = true)\n",
      " |-- blurb: string (nullable = true)\n",
      " |-- state: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "223627"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/25 10:14:22 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: \n",
      " Schema: _c0\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/randi/Documents/pyspark_udemy/Jupyter+Notebooks+and+Datasets+AS+of+16MAY21/Jupyter_Notebooks_and_Datasets_AS_of_16MAY21/Practice/Datasets/kickstarter.csv\n",
      "+-----------+-----------------+------------------+\n",
      "|Column_Name|Null_Values_Count|Null_Value_Percent|\n",
      "+-----------+-----------------+------------------+\n",
      "|      blurb|             1488|0.6653937136392296|\n",
      "|      state|            13157| 5.883457722010312|\n",
      "+-----------+-----------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def null_value_calc(df):\n",
    "    null_columns_counts = []\n",
    "    numRows = df.count()\n",
    "    for k in df.columns:\n",
    "        nullRows = df.where(col(k).isNull()).count()\n",
    "        if(nullRows>0):\n",
    "            temp = k,nullRows,(nullRows/numRows)*100\n",
    "            null_columns_counts.append(temp)\n",
    "    return(null_columns_counts)\n",
    "\n",
    "null_columns_calc_list = null_value_calc(df)\n",
    "spark.createDataFrame(null_columns_calc_list, ['Column_Name', 'Null_Values_Count','Null_Value_Percent']).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/25 10:14:24 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , blurb, state\n",
      " Schema: _c0, blurb, state\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/randi/Documents/pyspark_udemy/Jupyter+Notebooks+and+Datasets+AS+of+16MAY21/Jupyter_Notebooks_and_Datasets_AS_of_16MAY21/Practice/Datasets/kickstarter.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "210470"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.na.drop().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/25 10:14:24 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , blurb, state\n",
      " Schema: _c0, blurb, state\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/randi/Documents/pyspark_udemy/Jupyter+Notebooks+and+Datasets+AS+of+16MAY21/Jupyter_Notebooks_and_Datasets_AS_of_16MAY21/Practice/Datasets/kickstarter.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "210470"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/25 10:14:24 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , blurb, state\n",
      " Schema: _c0, blurb, state\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/randi/Documents/pyspark_udemy/Jupyter+Notebooks+and+Datasets+AS+of+16MAY21/Jupyter_Notebooks_and_Datasets_AS_of_16MAY21/Practice/Datasets/kickstarter.csv\n",
      "+--------------------+------+\n",
      "|               state| count|\n",
      "+--------------------+------+\n",
      "|          successful|103582|\n",
      "|              failed|102000|\n",
      "| and get some col...|     8|\n",
      "|          \",\"failed\"|     6|\n",
      "|     their childhood|     6|\n",
      "|                love|     6|\n",
      "| about a lonely f...|     5|\n",
      "|             romance|     4|\n",
      "|              poetry|     4|\n",
      "|            mastered|     4|\n",
      "|                  CD|     3|\n",
      "| She Wrote\"\" but ...|     3|\n",
      "|               music|     3|\n",
      "|                NY.\"|     3|\n",
      "|              2015.\"|     3|\n",
      "|            equality|     3|\n",
      "|               2014\"|     3|\n",
      "|              2014.\"|     3|\n",
      "|             Texas.\"|     3|\n",
      "|              2011.\"|     3|\n",
      "+--------------------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy(\"state\").count().orderBy(col(\"count\").desc()).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.filter(\"state IN('successful','failed')\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/25 10:14:25 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , blurb, state\n",
      " Schema: _c0, blurb, state\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/randi/Documents/pyspark_udemy/Jupyter+Notebooks+and+Datasets+AS+of+16MAY21/Jupyter_Notebooks_and_Datasets_AS_of_16MAY21/Practice/Datasets/kickstarter.csv\n",
      "+----------+------+\n",
      "|     state| count|\n",
      "+----------+------+\n",
      "|successful|103582|\n",
      "|    failed|102000|\n",
      "+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy(\"state\").count().orderBy(col(\"count\").desc()).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/25 10:14:25 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , blurb, state\n",
      " Schema: _c0, blurb, state\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/randi/Documents/pyspark_udemy/Jupyter+Notebooks+and+Datasets+AS+of+16MAY21/Jupyter_Notebooks_and_Datasets_AS_of_16MAY21/Practice/Datasets/kickstarter.csv\n",
      "+-----------------------------------------------------------------------------------------------------------------------------------+\n",
      "|blurb                                                                                                                              |\n",
      "+-----------------------------------------------------------------------------------------------------------------------------------+\n",
      "|Using their own character, users go on educational quests around a virtual world leveling up subject-oriented skills (ie Physics). |\n",
      "|MicroFly is a quadcopter packed with WiFi, 6 sensors, and 3 processors for ultimate stability -- and fits in the palm of your hand.|\n",
      "|A small indie press, run as a collective for authors who want to self-publish, and a sexy, smart , hilarious novel!                |\n",
      "|Zylor is a new baby cosplayer! Back this kickstarter to help fund new cosplay photoshoots to share his cuteness with the world!    |\n",
      "|Hatoful Boyfriend meet Skeletons! A comedy Dating Sim that puts you into a high school full of Skeletons. Rattle some Bones!       |\n",
      "|FastMan is a Infinite running platformer. Go in FastMan's shoes and run through the platform dodging obstacles.                    |\n",
      "|FADE. A dark and somber RPG about survival and hope.(Legend of Zelda/Fable Inspired)                                               |\n",
      "|The next generation of space combat with online progression, leveling, an arsenal of ships, weapons and much more!                 |\n",
      "|Whip around planets and smash your way to victory in this video game of galactic proportions!                                      |\n",
      "|Sneak in, find treasures, avoid cats and collect the loot before time runs out!                                                    |\n",
      "+-----------------------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(\"blurb\").show(10, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumn(\"blurb\", translate(col(\"blurb\"), \"/\",\" \")) \\\n",
    "    .withColumn(\"blurb\", translate(col(\"blurb\"), \"(\",\" \")) \\\n",
    "    .withColumn(\"blurb\", translate(col(\"blurb\"), \")\",\" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/25 10:14:25 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , blurb, state\n",
      " Schema: _c0, blurb, state\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/randi/Documents/pyspark_udemy/Jupyter+Notebooks+and+Datasets+AS+of+16MAY21/Jupyter_Notebooks_and_Datasets_AS_of_16MAY21/Practice/Datasets/kickstarter.csv\n",
      "+-----------------------------------------------------------------------------------------------------------------------------------+\n",
      "|blurb                                                                                                                              |\n",
      "+-----------------------------------------------------------------------------------------------------------------------------------+\n",
      "|Using their own character, users go on educational quests around a virtual world leveling up subject-oriented skills  ie Physics . |\n",
      "|MicroFly is a quadcopter packed with WiFi, 6 sensors, and 3 processors for ultimate stability -- and fits in the palm of your hand.|\n",
      "|A small indie press, run as a collective for authors who want to self-publish, and a sexy, smart , hilarious novel!                |\n",
      "|Zylor is a new baby cosplayer! Back this kickstarter to help fund new cosplay photoshoots to share his cuteness with the world!    |\n",
      "|Hatoful Boyfriend meet Skeletons! A comedy Dating Sim that puts you into a high school full of Skeletons. Rattle some Bones!       |\n",
      "|FastMan is a Infinite running platformer. Go in FastMan's shoes and run through the platform dodging obstacles.                    |\n",
      "|FADE. A dark and somber RPG about survival and hope. Legend of Zelda Fable Inspired                                                |\n",
      "|The next generation of space combat with online progression, leveling, an arsenal of ships, weapons and much more!                 |\n",
      "|Whip around planets and smash your way to victory in this video game of galactic proportions!                                      |\n",
      "|Sneak in, find treasures, avoid cats and collect the loot before time runs out!                                                    |\n",
      "+-----------------------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(\"blurb\").show(10, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumn(\"blurb\", regexp_replace(col(\"blurb\"), \"[^A-Za-z ]+\", \"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/25 10:14:25 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , blurb, state\n",
      " Schema: _c0, blurb, state\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/randi/Documents/pyspark_udemy/Jupyter+Notebooks+and+Datasets+AS+of+16MAY21/Jupyter_Notebooks_and_Datasets_AS_of_16MAY21/Practice/Datasets/kickstarter.csv\n",
      "+-------------------------------------------------------------------------------------------------------------------------------+\n",
      "|blurb                                                                                                                          |\n",
      "+-------------------------------------------------------------------------------------------------------------------------------+\n",
      "|Using their own character users go on educational quests around a virtual world leveling up subjectoriented skills  ie Physics |\n",
      "|MicroFly is a quadcopter packed with WiFi  sensors and  processors for ultimate stability  and fits in the palm of your hand   |\n",
      "|A small indie press run as a collective for authors who want to selfpublish and a sexy smart  hilarious novel                  |\n",
      "|Zylor is a new baby cosplayer Back this kickstarter to help fund new cosplay photoshoots to share his cuteness with the world  |\n",
      "|Hatoful Boyfriend meet Skeletons A comedy Dating Sim that puts you into a high school full of Skeletons Rattle some Bones      |\n",
      "|FastMan is a Infinite running platformer Go in FastMans shoes and run through the platform dodging obstacles                   |\n",
      "|FADE A dark and somber RPG about survival and hope Legend of Zelda Fable Inspired                                              |\n",
      "|The next generation of space combat with online progression leveling an arsenal of ships weapons and much more                 |\n",
      "|Whip around planets and smash your way to victory in this video game of galactic proportions                                   |\n",
      "|Sneak in find treasures avoid cats and collect the loot before time runs out                                                   |\n",
      "+-------------------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(\"blurb\").show(10, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumn(\"blurb\", regexp_replace(col(\"blurb\"), \" +\", \" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/25 10:14:26 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , blurb, state\n",
      " Schema: _c0, blurb, state\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/randi/Documents/pyspark_udemy/Jupyter+Notebooks+and+Datasets+AS+of+16MAY21/Jupyter_Notebooks_and_Datasets_AS_of_16MAY21/Practice/Datasets/kickstarter.csv\n",
      "+------------------------------------------------------------------------------------------------------------------------------+\n",
      "|blurb                                                                                                                         |\n",
      "+------------------------------------------------------------------------------------------------------------------------------+\n",
      "|Using their own character users go on educational quests around a virtual world leveling up subjectoriented skills ie Physics |\n",
      "|MicroFly is a quadcopter packed with WiFi sensors and processors for ultimate stability and fits in the palm of your hand     |\n",
      "|A small indie press run as a collective for authors who want to selfpublish and a sexy smart hilarious novel                  |\n",
      "|Zylor is a new baby cosplayer Back this kickstarter to help fund new cosplay photoshoots to share his cuteness with the world |\n",
      "|Hatoful Boyfriend meet Skeletons A comedy Dating Sim that puts you into a high school full of Skeletons Rattle some Bones     |\n",
      "|FastMan is a Infinite running platformer Go in FastMans shoes and run through the platform dodging obstacles                  |\n",
      "|FADE A dark and somber RPG about survival and hope Legend of Zelda Fable Inspired                                             |\n",
      "|The next generation of space combat with online progression leveling an arsenal of ships weapons and much more                |\n",
      "|Whip around planets and smash your way to victory in this video game of galactic proportions                                  |\n",
      "|Sneak in find treasures avoid cats and collect the loot before time runs out                                                  |\n",
      "+------------------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(\"blurb\").show(10, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumn(\"blurb\", lower(col(\"blurb\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/25 10:14:26 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , blurb, state\n",
      " Schema: _c0, blurb, state\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/randi/Documents/pyspark_udemy/Jupyter+Notebooks+and+Datasets+AS+of+16MAY21/Jupyter_Notebooks_and_Datasets_AS_of_16MAY21/Practice/Datasets/kickstarter.csv\n",
      "+------------------------------------------------------------------------------------------------------------------------------+\n",
      "|blurb                                                                                                                         |\n",
      "+------------------------------------------------------------------------------------------------------------------------------+\n",
      "|using their own character users go on educational quests around a virtual world leveling up subjectoriented skills ie physics |\n",
      "|microfly is a quadcopter packed with wifi sensors and processors for ultimate stability and fits in the palm of your hand     |\n",
      "|a small indie press run as a collective for authors who want to selfpublish and a sexy smart hilarious novel                  |\n",
      "|zylor is a new baby cosplayer back this kickstarter to help fund new cosplay photoshoots to share his cuteness with the world |\n",
      "|hatoful boyfriend meet skeletons a comedy dating sim that puts you into a high school full of skeletons rattle some bones     |\n",
      "|fastman is a infinite running platformer go in fastmans shoes and run through the platform dodging obstacles                  |\n",
      "|fade a dark and somber rpg about survival and hope legend of zelda fable inspired                                             |\n",
      "|the next generation of space combat with online progression leveling an arsenal of ships weapons and much more                |\n",
      "|whip around planets and smash your way to victory in this video game of galactic proportions                                  |\n",
      "|sneak in find treasures avoid cats and collect the loot before time runs out                                                  |\n",
      "+------------------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(\"blurb\").show(10, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/25 10:14:26 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , blurb, state\n",
      " Schema: _c0, blurb, state\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/randi/Documents/pyspark_udemy/Jupyter+Notebooks+and+Datasets+AS+of+16MAY21/Jupyter_Notebooks_and_Datasets_AS_of_16MAY21/Practice/Datasets/kickstarter.csv\n",
      "+---+------------------------------------------------------------------------------------------------------------------------------+----------+-------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|_c0|blurb                                                                                                                         |state     |words                                                                                                                                            |\n",
      "+---+------------------------------------------------------------------------------------------------------------------------------+----------+-------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|1  |using their own character users go on educational quests around a virtual world leveling up subjectoriented skills ie physics |failed    |[using, their, own, character, users, go, on, educational, quests, around, a, virtual, world, leveling, up, subjectoriented, skills, ie, physics]|\n",
      "|2  |microfly is a quadcopter packed with wifi sensors and processors for ultimate stability and fits in the palm of your hand     |successful|[microfly, is, a, quadcopter, packed, with, wifi, sensors, and, processors, for, ultimate, stability, and, fits, in, the, palm, of, your, hand]  |\n",
      "+---+------------------------------------------------------------------------------------------------------------------------------+----------+-------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "regex_tokenizer = RegexTokenizer(inputCol = \"blurb\", outputCol = \"words\", pattern = \"\\\\W\")\n",
    "raw_words = regex_tokenizer.transform(df)\n",
    "raw_words.show(2, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _c0: string (nullable = true)\n",
      " |-- blurb: string (nullable = true)\n",
      " |-- state: string (nullable = true)\n",
      " |-- words: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "raw_words.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "remover = StopWordsRemover(inputCol=\"words\", outputCol = \"filtered\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', 'your']"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords = remover.getStopWords()\n",
    "stopwords[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_df = remover.transform(raw_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/25 10:14:27 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , blurb, state\n",
      " Schema: _c0, blurb, state\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/randi/Documents/pyspark_udemy/Jupyter+Notebooks+and+Datasets+AS+of+16MAY21/Jupyter_Notebooks_and_Datasets_AS_of_16MAY21/Practice/Datasets/kickstarter.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_c0</th>\n",
       "      <th>blurb</th>\n",
       "      <th>state</th>\n",
       "      <th>words</th>\n",
       "      <th>filtered</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>using their own character users go on educatio...</td>\n",
       "      <td>failed</td>\n",
       "      <td>[using, their, own, character, users, go, on, ...</td>\n",
       "      <td>[using, character, users, go, educational, que...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>microfly is a quadcopter packed with wifi sens...</td>\n",
       "      <td>successful</td>\n",
       "      <td>[microfly, is, a, quadcopter, packed, with, wi...</td>\n",
       "      <td>[microfly, quadcopter, packed, wifi, sensors, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>a small indie press run as a collective for au...</td>\n",
       "      <td>failed</td>\n",
       "      <td>[a, small, indie, press, run, as, a, collectiv...</td>\n",
       "      <td>[small, indie, press, run, collective, authors...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>zylor is a new baby cosplayer back this kickst...</td>\n",
       "      <td>failed</td>\n",
       "      <td>[zylor, is, a, new, baby, cosplayer, back, thi...</td>\n",
       "      <td>[zylor, new, baby, cosplayer, back, kickstarte...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  _c0                                              blurb       state  \\\n",
       "0   1  using their own character users go on educatio...      failed   \n",
       "1   2  microfly is a quadcopter packed with wifi sens...  successful   \n",
       "2   3  a small indie press run as a collective for au...      failed   \n",
       "3   4  zylor is a new baby cosplayer back this kickst...      failed   \n",
       "\n",
       "                                               words  \\\n",
       "0  [using, their, own, character, users, go, on, ...   \n",
       "1  [microfly, is, a, quadcopter, packed, with, wi...   \n",
       "2  [a, small, indie, press, run, as, a, collectiv...   \n",
       "3  [zylor, is, a, new, baby, cosplayer, back, thi...   \n",
       "\n",
       "                                            filtered  \n",
       "0  [using, character, users, go, educational, que...  \n",
       "1  [microfly, quadcopter, packed, wifi, sensors, ...  \n",
       "2  [small, indie, press, run, collective, authors...  \n",
       "3  [zylor, new, baby, cosplayer, back, kickstarte...  "
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_df.limit(4).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/25 10:14:27 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , blurb, state\n",
      " Schema: _c0, blurb, state\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/randi/Documents/pyspark_udemy/Jupyter+Notebooks+and+Datasets+AS+of+16MAY21/Jupyter_Notebooks_and_Datasets_AS_of_16MAY21/Practice/Datasets/kickstarter.csv\n"
     ]
    }
   ],
   "source": [
    "indexer = StringIndexer(inputCol='state', outputCol='label')\n",
    "feature_data = indexer.fit(words_df).transform(words_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/25 10:14:27 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , blurb, state\n",
      " Schema: _c0, blurb, state\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/randi/Documents/pyspark_udemy/Jupyter+Notebooks+and+Datasets+AS+of+16MAY21/Jupyter_Notebooks_and_Datasets_AS_of_16MAY21/Practice/Datasets/kickstarter.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_c0</th>\n",
       "      <th>blurb</th>\n",
       "      <th>state</th>\n",
       "      <th>words</th>\n",
       "      <th>filtered</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>using their own character users go on educatio...</td>\n",
       "      <td>failed</td>\n",
       "      <td>[using, their, own, character, users, go, on, ...</td>\n",
       "      <td>[using, character, users, go, educational, que...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>microfly is a quadcopter packed with wifi sens...</td>\n",
       "      <td>successful</td>\n",
       "      <td>[microfly, is, a, quadcopter, packed, with, wi...</td>\n",
       "      <td>[microfly, quadcopter, packed, wifi, sensors, ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>a small indie press run as a collective for au...</td>\n",
       "      <td>failed</td>\n",
       "      <td>[a, small, indie, press, run, as, a, collectiv...</td>\n",
       "      <td>[small, indie, press, run, collective, authors...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>zylor is a new baby cosplayer back this kickst...</td>\n",
       "      <td>failed</td>\n",
       "      <td>[zylor, is, a, new, baby, cosplayer, back, thi...</td>\n",
       "      <td>[zylor, new, baby, cosplayer, back, kickstarte...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  _c0                                              blurb       state  \\\n",
       "0   1  using their own character users go on educatio...      failed   \n",
       "1   2  microfly is a quadcopter packed with wifi sens...  successful   \n",
       "2   3  a small indie press run as a collective for au...      failed   \n",
       "3   4  zylor is a new baby cosplayer back this kickst...      failed   \n",
       "\n",
       "                                               words  \\\n",
       "0  [using, their, own, character, users, go, on, ...   \n",
       "1  [microfly, is, a, quadcopter, packed, with, wi...   \n",
       "2  [a, small, indie, press, run, as, a, collectiv...   \n",
       "3  [zylor, is, a, new, baby, cosplayer, back, thi...   \n",
       "\n",
       "                                            filtered  label  \n",
       "0  [using, character, users, go, educational, que...    1.0  \n",
       "1  [microfly, quadcopter, packed, wifi, sensors, ...    0.0  \n",
       "2  [small, indie, press, run, collective, authors...    1.0  \n",
       "3  [zylor, new, baby, cosplayer, back, kickstarte...    1.0  "
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_data.limit(4).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/25 10:14:27 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , blurb, state\n",
      " Schema: _c0, blurb, state\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/randi/Documents/pyspark_udemy/Jupyter+Notebooks+and+Datasets+AS+of+16MAY21/Jupyter_Notebooks_and_Datasets_AS_of_16MAY21/Practice/Datasets/kickstarter.csv\n",
      "23/01/25 10:14:28 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , blurb, state\n",
      " Schema: _c0, blurb, state\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/randi/Documents/pyspark_udemy/Jupyter+Notebooks+and+Datasets+AS+of+16MAY21/Jupyter_Notebooks_and_Datasets_AS_of_16MAY21/Practice/Datasets/kickstarter.csv\n",
      "+---+------------------------------------------------------------------------------------------------------------------------------+------+-------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------+-----+\n",
      "|_c0|blurb                                                                                                                         |state |words                                                                                                                                            |filtered                                                                                                                  |label|\n",
      "+---+------------------------------------------------------------------------------------------------------------------------------+------+-------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------+-----+\n",
      "|1  |using their own character users go on educational quests around a virtual world leveling up subjectoriented skills ie physics |failed|[using, their, own, character, users, go, on, educational, quests, around, a, virtual, world, leveling, up, subjectoriented, skills, ie, physics]|[using, character, users, go, educational, quests, around, virtual, world, leveling, subjectoriented, skills, ie, physics]|1.0  |\n",
      "+---+------------------------------------------------------------------------------------------------------------------------------+------+-------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------+-----+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "############################ BEFORE ###############################\n",
    "regex_tokenizer = RegexTokenizer(inputCol = \"blurb\", outputCol = \"words\", pattern = \"\\\\W\")\n",
    "raw_words = regex_tokenizer.transform(df)\n",
    "\n",
    "remover = StopWordsRemover(inputCol=\"words\", outputCol = \"filtered\")\n",
    "words_df = remover.transform(raw_words)\n",
    "\n",
    "indexer = StringIndexer(inputCol='state', outputCol='label')\n",
    "feature_data = indexer.fit(words_df).transform(words_df)\n",
    "\n",
    "feature_data.show(1, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/25 10:14:28 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , blurb, state\n",
      " Schema: _c0, blurb, state\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/randi/Documents/pyspark_udemy/Jupyter+Notebooks+and+Datasets+AS+of+16MAY21/Jupyter_Notebooks_and_Datasets_AS_of_16MAY21/Practice/Datasets/kickstarter.csv\n",
      "23/01/25 10:14:28 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , blurb, state\n",
      " Schema: _c0, blurb, state\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/randi/Documents/pyspark_udemy/Jupyter+Notebooks+and+Datasets+AS+of+16MAY21/Jupyter_Notebooks_and_Datasets_AS_of_16MAY21/Practice/Datasets/kickstarter.csv\n",
      "+---+------------------------------------------------------------------------------------------------------------------------------+------+-------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------+-----+\n",
      "|_c0|blurb                                                                                                                         |state |words                                                                                                                                            |filtered                                                                                                                  |label|\n",
      "+---+------------------------------------------------------------------------------------------------------------------------------+------+-------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------+-----+\n",
      "|1  |using their own character users go on educational quests around a virtual world leveling up subjectoriented skills ie physics |failed|[using, their, own, character, users, go, on, educational, quests, around, a, virtual, world, leveling, up, subjectoriented, skills, ie, physics]|[using, character, users, go, educational, quests, around, virtual, world, leveling, subjectoriented, skills, ie, physics]|1.0  |\n",
      "+---+------------------------------------------------------------------------------------------------------------------------------+------+-------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------+-----+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "############################ AFTER ###############################\n",
    "regex_tokenizer = RegexTokenizer(inputCol = \"blurb\", outputCol = \"words\", pattern = \"\\\\W\")\n",
    "# raw_words = regex_tokenizer.transform(df)\n",
    "\n",
    "remover = StopWordsRemover(inputCol=regex_tokenizer.getOutputCol(), outputCol = \"filtered\")\n",
    "# words_df = remover.transform(raw_words)\n",
    "\n",
    "indexer = StringIndexer(inputCol='state', outputCol='label')\n",
    "#feature_data = indexer.fit(words_df).transform(words_df)\n",
    "\n",
    "pipeline = Pipeline(stages=[regex_tokenizer, remover, indexer])\n",
    "data_prep_pl = pipeline.fit(df)\n",
    "\n",
    "feature_data = data_prep_pl.transform(df)\n",
    "\n",
    "feature_data.show(1, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/25 10:14:28 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , blurb, state\n",
      " Schema: _c0, blurb, state\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/randi/Documents/pyspark_udemy/Jupyter+Notebooks+and+Datasets+AS+of+16MAY21/Jupyter_Notebooks_and_Datasets_AS_of_16MAY21/Practice/Datasets/kickstarter.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_c0</th>\n",
       "      <th>blurb</th>\n",
       "      <th>state</th>\n",
       "      <th>words</th>\n",
       "      <th>filtered</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>using their own character users go on educatio...</td>\n",
       "      <td>failed</td>\n",
       "      <td>[using, their, own, character, users, go, on, ...</td>\n",
       "      <td>[using, character, users, go, educational, que...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>microfly is a quadcopter packed with wifi sens...</td>\n",
       "      <td>successful</td>\n",
       "      <td>[microfly, is, a, quadcopter, packed, with, wi...</td>\n",
       "      <td>[microfly, quadcopter, packed, wifi, sensors, ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>a small indie press run as a collective for au...</td>\n",
       "      <td>failed</td>\n",
       "      <td>[a, small, indie, press, run, as, a, collectiv...</td>\n",
       "      <td>[small, indie, press, run, collective, authors...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>zylor is a new baby cosplayer back this kickst...</td>\n",
       "      <td>failed</td>\n",
       "      <td>[zylor, is, a, new, baby, cosplayer, back, thi...</td>\n",
       "      <td>[zylor, new, baby, cosplayer, back, kickstarte...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>hatoful boyfriend meet skeletons a comedy dati...</td>\n",
       "      <td>failed</td>\n",
       "      <td>[hatoful, boyfriend, meet, skeletons, a, comed...</td>\n",
       "      <td>[hatoful, boyfriend, meet, skeletons, comedy, ...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  _c0                                              blurb       state  \\\n",
       "0   1  using their own character users go on educatio...      failed   \n",
       "1   2  microfly is a quadcopter packed with wifi sens...  successful   \n",
       "2   3  a small indie press run as a collective for au...      failed   \n",
       "3   4  zylor is a new baby cosplayer back this kickst...      failed   \n",
       "4   5  hatoful boyfriend meet skeletons a comedy dati...      failed   \n",
       "\n",
       "                                               words  \\\n",
       "0  [using, their, own, character, users, go, on, ...   \n",
       "1  [microfly, is, a, quadcopter, packed, with, wi...   \n",
       "2  [a, small, indie, press, run, as, a, collectiv...   \n",
       "3  [zylor, is, a, new, baby, cosplayer, back, thi...   \n",
       "4  [hatoful, boyfriend, meet, skeletons, a, comed...   \n",
       "\n",
       "                                            filtered  label  \n",
       "0  [using, character, users, go, educational, que...    1.0  \n",
       "1  [microfly, quadcopter, packed, wifi, sensors, ...    0.0  \n",
       "2  [small, indie, press, run, collective, authors...    1.0  \n",
       "3  [zylor, new, baby, cosplayer, back, kickstarte...    1.0  \n",
       "4  [hatoful, boyfriend, meet, skeletons, comedy, ...    1.0  "
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_data.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "hashingTF = HashingTF(inputCol='filtered', outputCol='rawfeatures', numFeatures=20)\n",
    "HTFfeaturizedData = hashingTF.transform(feature_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/25 10:14:28 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , blurb, state\n",
      " Schema: _c0, blurb, state\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/randi/Documents/pyspark_udemy/Jupyter+Notebooks+and+Datasets+AS+of+16MAY21/Jupyter_Notebooks_and_Datasets_AS_of_16MAY21/Practice/Datasets/kickstarter.csv\n",
      "+---+------------------------------------------------------------------------------------------------------------------------------+------+-------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------+-----+-------------------------------------------------------------------------+\n",
      "|_c0|blurb                                                                                                                         |state |words                                                                                                                                            |filtered                                                                                                                  |label|rawfeatures                                                              |\n",
      "+---+------------------------------------------------------------------------------------------------------------------------------+------+-------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------+-----+-------------------------------------------------------------------------+\n",
      "|1  |using their own character users go on educational quests around a virtual world leveling up subjectoriented skills ie physics |failed|[using, their, own, character, users, go, on, educational, quests, around, a, virtual, world, leveling, up, subjectoriented, skills, ie, physics]|[using, character, users, go, educational, quests, around, virtual, world, leveling, subjectoriented, skills, ie, physics]|1.0  |(20,[0,2,6,7,9,11,15,16,17,18],[3.0,1.0,1.0,2.0,1.0,1.0,2.0,1.0,1.0,1.0])|\n",
      "+---+------------------------------------------------------------------------------------------------------------------------------+------+-------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------+-----+-------------------------------------------------------------------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "HTFfeaturizedData.show(1, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/25 10:14:29 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , blurb, state\n",
      " Schema: _c0, blurb, state\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/randi/Documents/pyspark_udemy/Jupyter+Notebooks+and+Datasets+AS+of+16MAY21/Jupyter_Notebooks_and_Datasets_AS_of_16MAY21/Practice/Datasets/kickstarter.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "idf = IDF(inputCol='rawfeatures', outputCol='features')\n",
    "idfModel = idf.fit(HTFfeaturizedData)\n",
    "TFIDFfeaturizedData = idfModel.transform(HTFfeaturizedData)\n",
    "TFIDFfeaturizedData.name = 'TFIDFfeaturizedData'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/25 10:14:32 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , blurb, state\n",
      " Schema: _c0, blurb, state\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/randi/Documents/pyspark_udemy/Jupyter+Notebooks+and+Datasets+AS+of+16MAY21/Jupyter_Notebooks_and_Datasets_AS_of_16MAY21/Practice/Datasets/kickstarter.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_c0</th>\n",
       "      <th>blurb</th>\n",
       "      <th>state</th>\n",
       "      <th>words</th>\n",
       "      <th>filtered</th>\n",
       "      <th>label</th>\n",
       "      <th>rawfeatures</th>\n",
       "      <th>features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>using their own character users go on educatio...</td>\n",
       "      <td>failed</td>\n",
       "      <td>[using, their, own, character, users, go, on, ...</td>\n",
       "      <td>[using, character, users, go, educational, que...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>(3.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 2.0, 0.0, ...</td>\n",
       "      <td>(2.252148827177929, 0.0, 0.8915391572399594, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>microfly is a quadcopter packed with wifi sens...</td>\n",
       "      <td>successful</td>\n",
       "      <td>[microfly, is, a, quadcopter, packed, with, wi...</td>\n",
       "      <td>[microfly, quadcopter, packed, wifi, sensors, ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>(1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 2.0, 1.0, ...</td>\n",
       "      <td>(0.7507162757259763, 0.9418501584120335, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>a small indie press run as a collective for au...</td>\n",
       "      <td>failed</td>\n",
       "      <td>[a, small, indie, press, run, as, a, collectiv...</td>\n",
       "      <td>[small, indie, press, run, collective, authors...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>(3.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, ...</td>\n",
       "      <td>(2.252148827177929, 0.0, 0.8915391572399594, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>zylor is a new baby cosplayer back this kickst...</td>\n",
       "      <td>failed</td>\n",
       "      <td>[zylor, is, a, new, baby, cosplayer, back, thi...</td>\n",
       "      <td>[zylor, new, baby, cosplayer, back, kickstarte...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>(2.0, 0.0, 0.0, 1.0, 1.0, 3.0, 0.0, 2.0, 2.0, ...</td>\n",
       "      <td>(1.5014325514519526, 0.0, 0.0, 0.6648665945302...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  _c0                                              blurb       state  \\\n",
       "0   1  using their own character users go on educatio...      failed   \n",
       "1   2  microfly is a quadcopter packed with wifi sens...  successful   \n",
       "2   3  a small indie press run as a collective for au...      failed   \n",
       "3   4  zylor is a new baby cosplayer back this kickst...      failed   \n",
       "\n",
       "                                               words  \\\n",
       "0  [using, their, own, character, users, go, on, ...   \n",
       "1  [microfly, is, a, quadcopter, packed, with, wi...   \n",
       "2  [a, small, indie, press, run, as, a, collectiv...   \n",
       "3  [zylor, is, a, new, baby, cosplayer, back, thi...   \n",
       "\n",
       "                                            filtered  label  \\\n",
       "0  [using, character, users, go, educational, que...    1.0   \n",
       "1  [microfly, quadcopter, packed, wifi, sensors, ...    0.0   \n",
       "2  [small, indie, press, run, collective, authors...    1.0   \n",
       "3  [zylor, new, baby, cosplayer, back, kickstarte...    1.0   \n",
       "\n",
       "                                         rawfeatures  \\\n",
       "0  (3.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 2.0, 0.0, ...   \n",
       "1  (1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 2.0, 1.0, ...   \n",
       "2  (3.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, ...   \n",
       "3  (2.0, 0.0, 0.0, 1.0, 1.0, 3.0, 0.0, 2.0, 2.0, ...   \n",
       "\n",
       "                                            features  \n",
       "0  (2.252148827177929, 0.0, 0.8915391572399594, 0...  \n",
       "1  (0.7507162757259763, 0.9418501584120335, 0.0, ...  \n",
       "2  (2.252148827177929, 0.0, 0.8915391572399594, 0...  \n",
       "3  (1.5014325514519526, 0.0, 0.0, 0.6648665945302...  "
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TFIDFfeaturizedData.limit(4).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "HTFfeaturizedData = HTFfeaturizedData.withColumnRenamed(\"rawfeatures\",\"features\")\n",
    "HTFfeaturizedData.name = 'HTFfeaturizedData'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/25 10:14:32 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , blurb, state\n",
      " Schema: _c0, blurb, state\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/randi/Documents/pyspark_udemy/Jupyter+Notebooks+and+Datasets+AS+of+16MAY21/Jupyter_Notebooks_and_Datasets_AS_of_16MAY21/Practice/Datasets/kickstarter.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/25 10:14:34 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , blurb, state\n",
      " Schema: _c0, blurb, state\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/randi/Documents/pyspark_udemy/Jupyter+Notebooks+and+Datasets+AS+of+16MAY21/Jupyter_Notebooks_and_Datasets_AS_of_16MAY21/Practice/Datasets/kickstarter.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/25 10:15:08 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , blurb, state\n",
      " Schema: _c0, blurb, state\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/randi/Documents/pyspark_udemy/Jupyter+Notebooks+and+Datasets+AS+of+16MAY21/Jupyter_Notebooks_and_Datasets_AS_of_16MAY21/Practice/Datasets/kickstarter.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_c0</th>\n",
       "      <th>blurb</th>\n",
       "      <th>state</th>\n",
       "      <th>words</th>\n",
       "      <th>filtered</th>\n",
       "      <th>label</th>\n",
       "      <th>features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>using their own character users go on educatio...</td>\n",
       "      <td>failed</td>\n",
       "      <td>[using, their, own, character, users, go, on, ...</td>\n",
       "      <td>[using, character, users, go, educational, que...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[0.14038110065406986, -0.24811659927114044, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>microfly is a quadcopter packed with wifi sens...</td>\n",
       "      <td>successful</td>\n",
       "      <td>[microfly, is, a, quadcopter, packed, with, wi...</td>\n",
       "      <td>[microfly, quadcopter, packed, wifi, sensors, ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[0.27672377347268845, -0.3168490545146845, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>a small indie press run as a collective for au...</td>\n",
       "      <td>failed</td>\n",
       "      <td>[a, small, indie, press, run, as, a, collectiv...</td>\n",
       "      <td>[small, indie, press, run, collective, authors...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[0.08995955561598142, 0.28520162504476804, 0.1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>zylor is a new baby cosplayer back this kickst...</td>\n",
       "      <td>failed</td>\n",
       "      <td>[zylor, is, a, new, baby, cosplayer, back, thi...</td>\n",
       "      <td>[zylor, new, baby, cosplayer, back, kickstarte...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[0.24012657121888228, 0.25589268415101935, 0.1...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  _c0                                              blurb       state  \\\n",
       "0   1  using their own character users go on educatio...      failed   \n",
       "1   2  microfly is a quadcopter packed with wifi sens...  successful   \n",
       "2   3  a small indie press run as a collective for au...      failed   \n",
       "3   4  zylor is a new baby cosplayer back this kickst...      failed   \n",
       "\n",
       "                                               words  \\\n",
       "0  [using, their, own, character, users, go, on, ...   \n",
       "1  [microfly, is, a, quadcopter, packed, with, wi...   \n",
       "2  [a, small, indie, press, run, as, a, collectiv...   \n",
       "3  [zylor, is, a, new, baby, cosplayer, back, thi...   \n",
       "\n",
       "                                            filtered  label  \\\n",
       "0  [using, character, users, go, educational, que...    1.0   \n",
       "1  [microfly, quadcopter, packed, wifi, sensors, ...    0.0   \n",
       "2  [small, indie, press, run, collective, authors...    1.0   \n",
       "3  [zylor, new, baby, cosplayer, back, kickstarte...    1.0   \n",
       "\n",
       "                                            features  \n",
       "0  [0.14038110065406986, -0.24811659927114044, 0....  \n",
       "1  [0.27672377347268845, -0.3168490545146845, -0....  \n",
       "2  [0.08995955561598142, 0.28520162504476804, 0.1...  \n",
       "3  [0.24012657121888228, 0.25589268415101935, 0.1...  "
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Word2Vec = Word2Vec(vectorSize=3, minCount=0, inputCol='filtered', outputCol='features')\n",
    "model = Word2Vec.fit(feature_data)\n",
    "\n",
    "W2VfeaturizedData = model.transform(feature_data)\n",
    "W2VfeaturizedData.limit(4).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/25 10:15:08 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , blurb, state\n",
      " Schema: _c0, blurb, state\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/randi/Documents/pyspark_udemy/Jupyter+Notebooks+and+Datasets+AS+of+16MAY21/Jupyter_Notebooks_and_Datasets_AS_of_16MAY21/Practice/Datasets/kickstarter.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 64:=======>                                                  (1 + 7) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/25 10:15:10 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , blurb, state\n",
      " Schema: _c0, blurb, state\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/randi/Documents/pyspark_udemy/Jupyter+Notebooks+and+Datasets+AS+of+16MAY21/Jupyter_Notebooks_and_Datasets_AS_of_16MAY21/Practice/Datasets/kickstarter.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_c0</th>\n",
       "      <th>blurb</th>\n",
       "      <th>state</th>\n",
       "      <th>words</th>\n",
       "      <th>filtered</th>\n",
       "      <th>label</th>\n",
       "      <th>features</th>\n",
       "      <th>scaledFeatures</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>using their own character users go on educatio...</td>\n",
       "      <td>failed</td>\n",
       "      <td>[using, their, own, character, users, go, on, ...</td>\n",
       "      <td>[using, character, users, go, educational, que...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[0.14038110065406986, -0.24811659927114044, 0....</td>\n",
       "      <td>[0.5792267598773768, 0.49325837641687337, 0.59...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>microfly is a quadcopter packed with wifi sens...</td>\n",
       "      <td>successful</td>\n",
       "      <td>[microfly, is, a, quadcopter, packed, with, wi...</td>\n",
       "      <td>[microfly, quadcopter, packed, wifi, sensors, ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[0.27672377347268845, -0.3168490545146845, -0....</td>\n",
       "      <td>[0.6256666184030814, 0.46945486621258775, 0.53...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>a small indie press run as a collective for au...</td>\n",
       "      <td>failed</td>\n",
       "      <td>[a, small, indie, press, run, as, a, collectiv...</td>\n",
       "      <td>[small, indie, press, run, collective, authors...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[0.08995955561598142, 0.28520162504476804, 0.1...</td>\n",
       "      <td>[0.5620526105827438, 0.6779578135263551, 0.657...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>zylor is a new baby cosplayer back this kickst...</td>\n",
       "      <td>failed</td>\n",
       "      <td>[zylor, is, a, new, baby, cosplayer, back, thi...</td>\n",
       "      <td>[zylor, new, baby, cosplayer, back, kickstarte...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[0.24012657121888228, 0.25589268415101935, 0.1...</td>\n",
       "      <td>[0.6132011968298638, 0.6678075043140753, 0.639...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  _c0                                              blurb       state  \\\n",
       "0   1  using their own character users go on educatio...      failed   \n",
       "1   2  microfly is a quadcopter packed with wifi sens...  successful   \n",
       "2   3  a small indie press run as a collective for au...      failed   \n",
       "3   4  zylor is a new baby cosplayer back this kickst...      failed   \n",
       "\n",
       "                                               words  \\\n",
       "0  [using, their, own, character, users, go, on, ...   \n",
       "1  [microfly, is, a, quadcopter, packed, with, wi...   \n",
       "2  [a, small, indie, press, run, as, a, collectiv...   \n",
       "3  [zylor, is, a, new, baby, cosplayer, back, thi...   \n",
       "\n",
       "                                            filtered  label  \\\n",
       "0  [using, character, users, go, educational, que...    1.0   \n",
       "1  [microfly, quadcopter, packed, wifi, sensors, ...    0.0   \n",
       "2  [small, indie, press, run, collective, authors...    1.0   \n",
       "3  [zylor, new, baby, cosplayer, back, kickstarte...    1.0   \n",
       "\n",
       "                                            features  \\\n",
       "0  [0.14038110065406986, -0.24811659927114044, 0....   \n",
       "1  [0.27672377347268845, -0.3168490545146845, -0....   \n",
       "2  [0.08995955561598142, 0.28520162504476804, 0.1...   \n",
       "3  [0.24012657121888228, 0.25589268415101935, 0.1...   \n",
       "\n",
       "                                      scaledFeatures  \n",
       "0  [0.5792267598773768, 0.49325837641687337, 0.59...  \n",
       "1  [0.6256666184030814, 0.46945486621258775, 0.53...  \n",
       "2  [0.5620526105827438, 0.6779578135263551, 0.657...  \n",
       "3  [0.6132011968298638, 0.6678075043140753, 0.639...  "
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = MinMaxScaler(inputCol='features', outputCol='scaledFeatures')\n",
    "scalerModel = scaler.fit(W2VfeaturizedData)\n",
    "scaled_data = scalerModel.transform(W2VfeaturizedData)\n",
    "scaled_data.limit(4).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "W2VfeaturizedData = scaled_data.select('state','blurb','label','scaledFeatures')\n",
    "W2VfeaturizedData = W2VfeaturizedData.withColumnRenamed('scaledFeatures','features')\n",
    "W2VfeaturizedData.name = 'W2VfeaturizedData'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/25 10:15:10 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , blurb, state\n",
      " Schema: _c0, blurb, state\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/randi/Documents/pyspark_udemy/Jupyter+Notebooks+and+Datasets+AS+of+16MAY21/Jupyter_Notebooks_and_Datasets_AS_of_16MAY21/Practice/Datasets/kickstarter.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>blurb</th>\n",
       "      <th>label</th>\n",
       "      <th>features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>failed</td>\n",
       "      <td>using their own character users go on educatio...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[0.5792267598773768, 0.49325837641687337, 0.59...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>successful</td>\n",
       "      <td>microfly is a quadcopter packed with wifi sens...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[0.6256666184030814, 0.46945486621258775, 0.53...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>failed</td>\n",
       "      <td>a small indie press run as a collective for au...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[0.5620526105827438, 0.6779578135263551, 0.657...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        state                                              blurb  label  \\\n",
       "0      failed  using their own character users go on educatio...    1.0   \n",
       "1  successful  microfly is a quadcopter packed with wifi sens...    0.0   \n",
       "2      failed  a small indie press run as a collective for au...    1.0   \n",
       "\n",
       "                                            features  \n",
       "0  [0.5792267598773768, 0.49325837641687337, 0.59...  \n",
       "1  [0.6256666184030814, 0.46945486621258775, 0.53...  \n",
       "2  [0.5620526105827438, 0.6779578135263551, 0.657...  "
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W2VfeaturizedData.limit(3).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ClassTrainEval(classifier,features,classes,train,test):\n",
    "\n",
    "    def FindMtype(classifier):\n",
    "        # Intstantiate Model\n",
    "        M = classifier\n",
    "        # Learn what it is\n",
    "        Mtype = type(M).__name__\n",
    "        \n",
    "        return Mtype\n",
    "    \n",
    "    Mtype = FindMtype(classifier)\n",
    "    \n",
    "\n",
    "    def IntanceFitModel(Mtype,classifier,classes,features,train):\n",
    "        \n",
    "        if Mtype == \"OneVsRest\":\n",
    "            # instantiate the base classifier.\n",
    "            lr = LogisticRegression()\n",
    "            # instantiate the One Vs Rest Classifier.\n",
    "            OVRclassifier = OneVsRest(classifier=lr)\n",
    "#             fitModel = OVRclassifier.fit(train)\n",
    "            # Add parameters of your choice here:\n",
    "            paramGrid = ParamGridBuilder() \\\n",
    "                .addGrid(lr.regParam, [0.1, 0.01]) \\\n",
    "                .build()\n",
    "            #Cross Validator requires the following parameters:\n",
    "            crossval = CrossValidator(estimator=OVRclassifier,\n",
    "                                      estimatorParamMaps=paramGrid,\n",
    "                                      evaluator=MulticlassClassificationEvaluator(),\n",
    "                                      numFolds=2) # 3 is best practice\n",
    "            # Run cross-validation, and choose the best set of parameters.\n",
    "            fitModel = crossval.fit(train)\n",
    "            return fitModel\n",
    "        if Mtype == \"MultilayerPerceptronClassifier\":\n",
    "            # specify layers for the neural network:\n",
    "            # input layer of size features, two intermediate of features+1 and same size as features\n",
    "            # and output of size number of classes\n",
    "            # Note: crossvalidator cannot be used here\n",
    "            features_count = len(features[0][0])\n",
    "            layers = [features_count, features_count+1, features_count, classes]\n",
    "            MPC_classifier = MultilayerPerceptronClassifier(maxIter=100, layers=layers, blockSize=128, seed=1234)\n",
    "            fitModel = MPC_classifier.fit(train)\n",
    "            return fitModel\n",
    "        if Mtype in(\"LinearSVC\",\"GBTClassifier\") and classes != 2: # These classifiers currently only accept binary classification\n",
    "            print(Mtype,\" could not be used because PySpark currently only accepts binary classification data for this algorithm\")\n",
    "            return\n",
    "        if Mtype in(\"LogisticRegression\",\"NaiveBayes\",\"RandomForestClassifier\",\"GBTClassifier\",\"LinearSVC\",\"DecisionTreeClassifier\"):\n",
    "  \n",
    "            # Add parameters of your choice here:\n",
    "            if Mtype in(\"LogisticRegression\"):\n",
    "                paramGrid = (ParamGridBuilder() \\\n",
    "#                              .addGrid(classifier.regParam, [0.1, 0.01]) \\\n",
    "                             .addGrid(classifier.maxIter, [10, 15,20])\n",
    "                             .build())\n",
    "                \n",
    "            # Add parameters of your choice here:\n",
    "            if Mtype in(\"NaiveBayes\"):\n",
    "                paramGrid = (ParamGridBuilder() \\\n",
    "                             .addGrid(classifier.smoothing, [0.0, 0.2, 0.4, 0.6]) \\\n",
    "                             .build())\n",
    "                \n",
    "            # Add parameters of your choice here:\n",
    "            if Mtype in(\"RandomForestClassifier\"):\n",
    "                paramGrid = (ParamGridBuilder() \\\n",
    "                               .addGrid(classifier.maxDepth, [2, 5, 10])\n",
    "#                                .addGrid(classifier.maxBins, [5, 10, 20])\n",
    "#                                .addGrid(classifier.numTrees, [5, 20, 50])\n",
    "                             .build())\n",
    "                \n",
    "            # Add parameters of your choice here:\n",
    "            if Mtype in(\"GBTClassifier\"):\n",
    "                paramGrid = (ParamGridBuilder() \\\n",
    "#                              .addGrid(classifier.maxDepth, [2, 5, 10, 20, 30]) \\\n",
    "#                              .addGrid(classifier.maxBins, [10, 20, 40, 80, 100]) \\\n",
    "                             .addGrid(classifier.maxIter, [10, 15,50,100])\n",
    "                             .build())\n",
    "                \n",
    "            # Add parameters of your choice here:\n",
    "            if Mtype in(\"LinearSVC\"):\n",
    "                paramGrid = (ParamGridBuilder() \\\n",
    "                             .addGrid(classifier.maxIter, [10, 15]) \\\n",
    "                             .addGrid(classifier.regParam, [0.1, 0.01]) \\\n",
    "                             .build())\n",
    "            \n",
    "            # Add parameters of your choice here:\n",
    "            if Mtype in(\"DecisionTreeClassifier\"):\n",
    "                paramGrid = (ParamGridBuilder() \\\n",
    "#                              .addGrid(classifier.maxDepth, [2, 5, 10, 20, 30]) \\\n",
    "                             .addGrid(classifier.maxBins, [10, 20, 40, 80, 100]) \\\n",
    "                             .build())\n",
    "            \n",
    "            #Cross Validator requires all of the following parameters:\n",
    "            crossval = CrossValidator(estimator=classifier,\n",
    "                                      estimatorParamMaps=paramGrid,\n",
    "                                      evaluator=MulticlassClassificationEvaluator(),\n",
    "                                      numFolds=2) # 3 + is best practice\n",
    "            # Fit Model: Run cross-validation, and choose the best set of parameters.\n",
    "            fitModel = crossval.fit(train)\n",
    "            return fitModel\n",
    "    \n",
    "    fitModel = IntanceFitModel(Mtype,classifier,classes,features,train)\n",
    "    \n",
    "    # Print feature selection metrics\n",
    "    if fitModel is not None:\n",
    "        \n",
    "        if Mtype in(\"OneVsRest\"):\n",
    "            # Get Best Model\n",
    "            BestModel = fitModel.bestModel\n",
    "            print(\" \")\n",
    "            print('\\033[1m' + Mtype + '\\033[0m')\n",
    "            # Extract list of binary models\n",
    "            models = BestModel.models\n",
    "            for model in models:\n",
    "                print('\\033[1m' + 'Intercept: '+ '\\033[0m',model.intercept,'\\033[1m' + '\\nCoefficients:'+ '\\033[0m',model.coefficients)\n",
    "\n",
    "        if Mtype == \"MultilayerPerceptronClassifier\":\n",
    "            print(\"\")\n",
    "            print('\\033[1m' + Mtype,\" Weights\"+ '\\033[0m')\n",
    "            print('\\033[1m' + \"Model Weights: \"+ '\\033[0m',fitModel.weights.size)\n",
    "            print(\"\")\n",
    "\n",
    "        if Mtype in(\"DecisionTreeClassifier\", \"GBTClassifier\",\"RandomForestClassifier\"):\n",
    "            # FEATURE IMPORTANCES\n",
    "            # Estimate of the importance of each feature.\n",
    "            # Each feature’s importance is the average of its importance across all trees \n",
    "            # in the ensemble The importance vector is normalized to sum to 1. \n",
    "            # Get Best Model\n",
    "            BestModel = fitModel.bestModel\n",
    "            print(\" \")\n",
    "            print('\\033[1m' + Mtype,\" Feature Importances\"+ '\\033[0m')\n",
    "            print(\"(Scores add up to 1)\")\n",
    "            print(\"Lowest score is the least important\")\n",
    "            print(\" \")\n",
    "            print(BestModel.featureImportances)\n",
    "            \n",
    "            if Mtype in(\"DecisionTreeClassifier\"):\n",
    "                global DT_featureimportances\n",
    "                DT_featureimportances = BestModel.featureImportances.toArray()\n",
    "                global DT_BestModel\n",
    "                DT_BestModel = BestModel\n",
    "            if Mtype in(\"GBTClassifier\"):\n",
    "                global GBT_featureimportances\n",
    "                GBT_featureimportances = BestModel.featureImportances.toArray()\n",
    "                global GBT_BestModel\n",
    "                GBT_BestModel = BestModel\n",
    "            if Mtype in(\"RandomForestClassifier\"):\n",
    "                global RF_featureimportances\n",
    "                RF_featureimportances = BestModel.featureImportances.toArray()\n",
    "                global RF_BestModel\n",
    "                RF_BestModel = BestModel\n",
    "\n",
    "        if Mtype in(\"LogisticRegression\"):\n",
    "            # Get Best Model\n",
    "            BestModel = fitModel.bestModel\n",
    "            print(\" \")\n",
    "            print('\\033[1m' + Mtype,\" Coefficient Matrix\"+ '\\033[0m')\n",
    "            print(\"You should compares these relative to eachother\")\n",
    "            print(\"Coefficients: \\n\" + str(BestModel.coefficientMatrix))\n",
    "            print(\"Intercept: \" + str(BestModel.interceptVector))\n",
    "            global LR_coefficients\n",
    "            LR_coefficients = BestModel.coefficientMatrix.toArray()\n",
    "            global LR_BestModel\n",
    "            LR_BestModel = BestModel\n",
    "\n",
    "        if Mtype in(\"LinearSVC\"):\n",
    "            # Get Best Model\n",
    "            BestModel = fitModel.bestModel\n",
    "            print(\" \")\n",
    "            print('\\033[1m' + Mtype,\" Coefficients\"+ '\\033[0m')\n",
    "            print(\"You should compares these relative to eachother\")\n",
    "            print(\"Coefficients: \\n\" + str(BestModel.coefficients))\n",
    "            global LSVC_coefficients\n",
    "            LSVC_coefficients = BestModel.coefficients.toArray()\n",
    "            global LSVC_BestModel\n",
    "            LSVC_BestModel = BestModel\n",
    "        \n",
    "   \n",
    "    # Set the column names to match the external results dataframe that we will join with later:\n",
    "    columns = ['Classifier', 'Result']\n",
    "    \n",
    "    if Mtype in(\"LinearSVC\",\"GBTClassifier\") and classes != 2:\n",
    "        Mtype = [Mtype] # make this a list\n",
    "        score = [\"N/A\"]\n",
    "        result = spark.createDataFrame(zip(Mtype,score), schema=columns)\n",
    "    else:\n",
    "        predictions = fitModel.transform(test)\n",
    "        MC_evaluator = MulticlassClassificationEvaluator(metricName=\"accuracy\") # redictionCol=\"prediction\",\n",
    "        accuracy = (MC_evaluator.evaluate(predictions))*100\n",
    "        Mtype = [Mtype] # make this a string\n",
    "        score = [str(accuracy)] #make this a string and convert to a list\n",
    "        result = spark.createDataFrame(zip(Mtype,score), schema=columns)\n",
    "        result = result.withColumn('Result',result.Result.substr(0, 5))\n",
    "        \n",
    "    return result\n",
    "    #Also returns the fit model important scores or p values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pyspark.ml.classification import *\n",
    "# from pyspark.ml.evaluation import *\n",
    "# from pyspark.sql import functions\n",
    "# from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "\n",
    "# Comment out Naive Bayes if your data still contains negative values\n",
    "classifiers = [\n",
    "                LogisticRegression()\n",
    "                ,OneVsRest()\n",
    "               ,LinearSVC()\n",
    "               ,NaiveBayes()\n",
    "               ,RandomForestClassifier()\n",
    "               ,GBTClassifier()\n",
    "               ,DecisionTreeClassifier()\n",
    "               ,MultilayerPerceptronClassifier()\n",
    "              ] \n",
    "\n",
    "featureDF_list = [HTFfeaturizedData,TFIDFfeaturizedData,W2VfeaturizedData]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTFfeaturizedData\n",
      "23/01/25 10:15:10 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , blurb, state\n",
      " Schema: _c0, blurb, state\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/randi/Documents/pyspark_udemy/Jupyter+Notebooks+and+Datasets+AS+of+16MAY21/Jupyter_Notebooks_and_Datasets_AS_of_16MAY21/Practice/Datasets/kickstarter.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/25 10:15:20 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , blurb, state\n",
      " Schema: _c0, blurb, state\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/randi/Documents/pyspark_udemy/Jupyter+Notebooks+and+Datasets+AS+of+16MAY21/Jupyter_Notebooks_and_Datasets_AS_of_16MAY21/Practice/Datasets/kickstarter.csv\n",
      "23/01/25 10:15:20 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , blurb, state\n",
      " Schema: _c0, blurb, state\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/randi/Documents/pyspark_udemy/Jupyter+Notebooks+and+Datasets+AS+of+16MAY21/Jupyter_Notebooks_and_Datasets_AS_of_16MAY21/Practice/Datasets/kickstarter.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/25 10:15:23 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , blurb, state\n",
      " Schema: _c0, blurb, state\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/randi/Documents/pyspark_udemy/Jupyter+Notebooks+and+Datasets+AS+of+16MAY21/Jupyter_Notebooks_and_Datasets_AS_of_16MAY21/Practice/Datasets/kickstarter.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/25 10:15:28 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , blurb, state\n",
      " Schema: _c0, blurb, state\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/randi/Documents/pyspark_udemy/Jupyter+Notebooks+and+Datasets+AS+of+16MAY21/Jupyter_Notebooks_and_Datasets_AS_of_16MAY21/Practice/Datasets/kickstarter.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/25 10:15:31 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , blurb, state\n",
      " Schema: _c0, blurb, state\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/randi/Documents/pyspark_udemy/Jupyter+Notebooks+and+Datasets+AS+of+16MAY21/Jupyter_Notebooks_and_Datasets_AS_of_16MAY21/Practice/Datasets/kickstarter.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/25 10:15:35 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , blurb, state\n",
      " Schema: _c0, blurb, state\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/randi/Documents/pyspark_udemy/Jupyter+Notebooks+and+Datasets+AS+of+16MAY21/Jupyter_Notebooks_and_Datasets_AS_of_16MAY21/Practice/Datasets/kickstarter.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/25 10:15:38 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , blurb, state\n",
      " Schema: _c0, blurb, state\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/randi/Documents/pyspark_udemy/Jupyter+Notebooks+and+Datasets+AS+of+16MAY21/Jupyter_Notebooks_and_Datasets_AS_of_16MAY21/Practice/Datasets/kickstarter.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "\u001b[1mLogisticRegression  Coefficient Matrix\u001b[0m\n",
      "You should compares these relative to eachother\n",
      "Coefficients: \n",
      "DenseMatrix([[-0.02572065,  0.00980701, -0.088554  ,  0.00511315, -0.01320951,\n",
      "              -0.11092766, -0.06282471, -0.02965198, -0.02699535, -0.03989592,\n",
      "               0.0620209 , -0.02636028,  0.008281  ,  0.011904  , -0.02740356,\n",
      "              -0.03212623,  0.01096433, -0.01975474, -0.08664516, -0.02448302]])\n",
      "Intercept: [0.26534368368354916]\n",
      "23/01/25 10:15:41 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , blurb, state\n",
      " Schema: _c0, blurb, state\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/randi/Documents/pyspark_udemy/Jupyter+Notebooks+and+Datasets+AS+of+16MAY21/Jupyter_Notebooks_and_Datasets_AS_of_16MAY21/Practice/Datasets/kickstarter.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/25 10:15:43 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , blurb, state\n",
      " Schema: _c0, blurb, state\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/randi/Documents/pyspark_udemy/Jupyter+Notebooks+and+Datasets+AS+of+16MAY21/Jupyter_Notebooks_and_Datasets_AS_of_16MAY21/Practice/Datasets/kickstarter.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/25 10:15:47 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , blurb, state\n",
      " Schema: _c0, blurb, state\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/randi/Documents/pyspark_udemy/Jupyter+Notebooks+and+Datasets+AS+of+16MAY21/Jupyter_Notebooks_and_Datasets_AS_of_16MAY21/Practice/Datasets/kickstarter.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/25 10:15:55 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , blurb, state\n",
      " Schema: _c0, blurb, state\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/randi/Documents/pyspark_udemy/Jupyter+Notebooks+and+Datasets+AS+of+16MAY21/Jupyter_Notebooks_and_Datasets_AS_of_16MAY21/Practice/Datasets/kickstarter.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/25 10:15:59 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , blurb, state\n",
      " Schema: _c0, blurb, state\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/randi/Documents/pyspark_udemy/Jupyter+Notebooks+and+Datasets+AS+of+16MAY21/Jupyter_Notebooks_and_Datasets_AS_of_16MAY21/Practice/Datasets/kickstarter.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/25 10:16:04 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , blurb, state\n",
      " Schema: _c0, blurb, state\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/randi/Documents/pyspark_udemy/Jupyter+Notebooks+and+Datasets+AS+of+16MAY21/Jupyter_Notebooks_and_Datasets_AS_of_16MAY21/Practice/Datasets/kickstarter.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/25 10:16:07 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , blurb, state\n",
      " Schema: _c0, blurb, state\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/randi/Documents/pyspark_udemy/Jupyter+Notebooks+and+Datasets+AS+of+16MAY21/Jupyter_Notebooks_and_Datasets_AS_of_16MAY21/Practice/Datasets/kickstarter.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/25 10:16:09 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , blurb, state\n",
      " Schema: _c0, blurb, state\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/randi/Documents/pyspark_udemy/Jupyter+Notebooks+and+Datasets+AS+of+16MAY21/Jupyter_Notebooks_and_Datasets_AS_of_16MAY21/Practice/Datasets/kickstarter.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/25 10:16:12 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , blurb, state\n",
      " Schema: _c0, blurb, state\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/randi/Documents/pyspark_udemy/Jupyter+Notebooks+and+Datasets+AS+of+16MAY21/Jupyter_Notebooks_and_Datasets_AS_of_16MAY21/Practice/Datasets/kickstarter.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/25 10:16:15 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , blurb, state\n",
      " Schema: _c0, blurb, state\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/randi/Documents/pyspark_udemy/Jupyter+Notebooks+and+Datasets+AS+of+16MAY21/Jupyter_Notebooks_and_Datasets_AS_of_16MAY21/Practice/Datasets/kickstarter.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "\u001b[1mOneVsRest\u001b[0m\n",
      "\u001b[1mIntercept: \u001b[0m -0.24966708207946395 \u001b[1m\n",
      "Coefficients:\u001b[0m [0.024372060540788193,-0.00994841415379913,0.08473275115426164,-0.005427777776882383,0.012376634801657429,0.1063781184477319,0.06005283878638654,0.028247085746463865,0.025650418899828553,0.0378644737787286,-0.05997341676615515,0.024862205166703018,-0.00848626005530521,-0.011889884431524765,0.02588601566411619,0.030410385016060353,-0.010888508709059953,0.018631174222811617,0.08300561917499781,0.02309112408260959]\n",
      "\u001b[1mIntercept: \u001b[0m 0.24966708207946361 \u001b[1m\n",
      "Coefficients:\u001b[0m [-0.02437206054078813,0.009948414153799146,-0.08473275115426164,0.005427777776882416,-0.012376634801657401,-0.10637811844773191,-0.060052838786386516,-0.028247085746463778,-0.02565041889982852,-0.0378644737787285,0.0599734167661552,-0.02486220516670301,0.00848626005530525,0.011889884431524783,-0.025886015664116163,-0.03041038501606038,0.010888508709059993,-0.018631174222811568,-0.08300561917499777,-0.023091124082609552]\n",
      "23/01/25 10:16:18 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , blurb, state\n",
      " Schema: _c0, blurb, state\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/randi/Documents/pyspark_udemy/Jupyter+Notebooks+and+Datasets+AS+of+16MAY21/Jupyter_Notebooks_and_Datasets_AS_of_16MAY21/Practice/Datasets/kickstarter.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/25 10:16:22 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , blurb, state\n",
      " Schema: _c0, blurb, state\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/randi/Documents/pyspark_udemy/Jupyter+Notebooks+and+Datasets+AS+of+16MAY21/Jupyter_Notebooks_and_Datasets_AS_of_16MAY21/Practice/Datasets/kickstarter.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/25 10:16:26 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , blurb, state\n",
      " Schema: _c0, blurb, state\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/randi/Documents/pyspark_udemy/Jupyter+Notebooks+and+Datasets+AS+of+16MAY21/Jupyter_Notebooks_and_Datasets_AS_of_16MAY21/Practice/Datasets/kickstarter.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/25 10:16:32 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , blurb, state\n",
      " Schema: _c0, blurb, state\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/randi/Documents/pyspark_udemy/Jupyter+Notebooks+and+Datasets+AS+of+16MAY21/Jupyter_Notebooks_and_Datasets_AS_of_16MAY21/Practice/Datasets/kickstarter.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/25 10:16:36 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , blurb, state\n",
      " Schema: _c0, blurb, state\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/randi/Documents/pyspark_udemy/Jupyter+Notebooks+and+Datasets+AS+of+16MAY21/Jupyter_Notebooks_and_Datasets_AS_of_16MAY21/Practice/Datasets/kickstarter.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/25 10:16:42 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , blurb, state\n",
      " Schema: _c0, blurb, state\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/randi/Documents/pyspark_udemy/Jupyter+Notebooks+and+Datasets+AS+of+16MAY21/Jupyter_Notebooks_and_Datasets_AS_of_16MAY21/Practice/Datasets/kickstarter.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/25 10:16:45 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , blurb, state\n",
      " Schema: _c0, blurb, state\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/randi/Documents/pyspark_udemy/Jupyter+Notebooks+and+Datasets+AS+of+16MAY21/Jupyter_Notebooks_and_Datasets_AS_of_16MAY21/Practice/Datasets/kickstarter.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "\u001b[1mLinearSVC  Coefficients\u001b[0m\n",
      "You should compares these relative to eachother\n",
      "Coefficients: \n",
      "[-0.0844997878755985,0.031759943522102374,-0.3049258512353981,0.008460503514691,-0.057563266478105564,-0.3425060183956073,-0.21622175468071517,-0.10375193060056877,-0.10953043629235756,-0.15253763967428516,0.18653044415594597,-0.10315178887654208,0.023845538956622416,0.04126341495774034,-0.10281309383420112,-0.1265405015923651,0.03474181079366454,-0.08327828896703647,-0.30038963501897914,-0.1011199529848215]\n",
      "23/01/25 10:16:48 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , blurb, state\n",
      " Schema: _c0, blurb, state\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/randi/Documents/pyspark_udemy/Jupyter+Notebooks+and+Datasets+AS+of+16MAY21/Jupyter_Notebooks_and_Datasets_AS_of_16MAY21/Practice/Datasets/kickstarter.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/25 10:16:51 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , blurb, state\n",
      " Schema: _c0, blurb, state\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/randi/Documents/pyspark_udemy/Jupyter+Notebooks+and+Datasets+AS+of+16MAY21/Jupyter_Notebooks_and_Datasets_AS_of_16MAY21/Practice/Datasets/kickstarter.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/25 10:16:53 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , blurb, state\n",
      " Schema: _c0, blurb, state\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/randi/Documents/pyspark_udemy/Jupyter+Notebooks+and+Datasets+AS+of+16MAY21/Jupyter_Notebooks_and_Datasets_AS_of_16MAY21/Practice/Datasets/kickstarter.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/25 10:16:57 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , blurb, state\n",
      " Schema: _c0, blurb, state\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/randi/Documents/pyspark_udemy/Jupyter+Notebooks+and+Datasets+AS+of+16MAY21/Jupyter_Notebooks_and_Datasets_AS_of_16MAY21/Practice/Datasets/kickstarter.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/25 10:16:59 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , blurb, state\n",
      " Schema: _c0, blurb, state\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/randi/Documents/pyspark_udemy/Jupyter+Notebooks+and+Datasets+AS+of+16MAY21/Jupyter_Notebooks_and_Datasets_AS_of_16MAY21/Practice/Datasets/kickstarter.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/25 10:17:03 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , blurb, state\n",
      " Schema: _c0, blurb, state\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/randi/Documents/pyspark_udemy/Jupyter+Notebooks+and+Datasets+AS+of+16MAY21/Jupyter_Notebooks_and_Datasets_AS_of_16MAY21/Practice/Datasets/kickstarter.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/25 10:17:06 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , blurb, state\n",
      " Schema: _c0, blurb, state\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/randi/Documents/pyspark_udemy/Jupyter+Notebooks+and+Datasets+AS+of+16MAY21/Jupyter_Notebooks_and_Datasets_AS_of_16MAY21/Practice/Datasets/kickstarter.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/25 10:17:08 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , blurb, state\n",
      " Schema: _c0, blurb, state\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/randi/Documents/pyspark_udemy/Jupyter+Notebooks+and+Datasets+AS+of+16MAY21/Jupyter_Notebooks_and_Datasets_AS_of_16MAY21/Practice/Datasets/kickstarter.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/25 10:17:12 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , blurb, state\n",
      " Schema: _c0, blurb, state\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/randi/Documents/pyspark_udemy/Jupyter+Notebooks+and+Datasets+AS+of+16MAY21/Jupyter_Notebooks_and_Datasets_AS_of_16MAY21/Practice/Datasets/kickstarter.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/25 10:17:17 WARN DAGScheduler: Broadcasting large task binary with size 1037.0 KiB\n",
      "23/01/25 10:17:17 WARN DAGScheduler: Broadcasting large task binary with size 1617.4 KiB\n",
      "23/01/25 10:17:18 WARN DAGScheduler: Broadcasting large task binary with size 1207.9 KiB\n",
      "23/01/25 10:17:18 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , blurb, state\n",
      " Schema: _c0, blurb, state\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/randi/Documents/pyspark_udemy/Jupyter+Notebooks+and+Datasets+AS+of+16MAY21/Jupyter_Notebooks_and_Datasets_AS_of_16MAY21/Practice/Datasets/kickstarter.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/25 10:17:22 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , blurb, state\n",
      " Schema: _c0, blurb, state\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/randi/Documents/pyspark_udemy/Jupyter+Notebooks+and+Datasets+AS+of+16MAY21/Jupyter_Notebooks_and_Datasets_AS_of_16MAY21/Practice/Datasets/kickstarter.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/25 10:17:27 WARN DAGScheduler: Broadcasting large task binary with size 1013.8 KiB\n",
      "23/01/25 10:17:28 WARN DAGScheduler: Broadcasting large task binary with size 1580.6 KiB\n",
      "23/01/25 10:17:28 WARN DAGScheduler: Broadcasting large task binary with size 1186.8 KiB\n",
      "23/01/25 10:17:28 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , blurb, state\n",
      " Schema: _c0, blurb, state\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/randi/Documents/pyspark_udemy/Jupyter+Notebooks+and+Datasets+AS+of+16MAY21/Jupyter_Notebooks_and_Datasets_AS_of_16MAY21/Practice/Datasets/kickstarter.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/25 10:17:30 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , blurb, state\n",
      " Schema: _c0, blurb, state\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/randi/Documents/pyspark_udemy/Jupyter+Notebooks+and+Datasets+AS+of+16MAY21/Jupyter_Notebooks_and_Datasets_AS_of_16MAY21/Practice/Datasets/kickstarter.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/25 10:17:32 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , blurb, state\n",
      " Schema: _c0, blurb, state\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/randi/Documents/pyspark_udemy/Jupyter+Notebooks+and+Datasets+AS+of+16MAY21/Jupyter_Notebooks_and_Datasets_AS_of_16MAY21/Practice/Datasets/kickstarter.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/25 10:17:34 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , blurb, state\n",
      " Schema: _c0, blurb, state\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/randi/Documents/pyspark_udemy/Jupyter+Notebooks+and+Datasets+AS+of+16MAY21/Jupyter_Notebooks_and_Datasets_AS_of_16MAY21/Practice/Datasets/kickstarter.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/25 10:17:39 WARN DAGScheduler: Broadcasting large task binary with size 1101.2 KiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/25 10:17:40 WARN DAGScheduler: Broadcasting large task binary with size 1784.1 KiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "\u001b[1mRandomForestClassifier  Feature Importances\u001b[0m\n",
      "(Scores add up to 1)\n",
      "Lowest score is the least important\n",
      " \n",
      "(20,[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19],[0.045816234845427864,0.04098253540308568,0.06687495617517647,0.04699095348664945,0.03969000479288093,0.10167573363505063,0.05051365472398783,0.04980753930155541,0.03891218894711769,0.04029211889435241,0.0698382097608313,0.043292329886329764,0.04502876834610426,0.04635343756553399,0.04331428754526033,0.043463097677385445,0.039649284821531815,0.043139437864290066,0.06192914072346034,0.042436085603988295])\n",
      "23/01/25 10:17:41 WARN DAGScheduler: Broadcasting large task binary with size 1332.0 KiB\n",
      "23/01/25 10:17:41 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , blurb, state\n",
      " Schema: _c0, blurb, state\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/randi/Documents/pyspark_udemy/Jupyter+Notebooks+and+Datasets+AS+of+16MAY21/Jupyter_Notebooks_and_Datasets_AS_of_16MAY21/Practice/Datasets/kickstarter.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/25 10:17:43 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , blurb, state\n",
      " Schema: _c0, blurb, state\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/randi/Documents/pyspark_udemy/Jupyter+Notebooks+and+Datasets+AS+of+16MAY21/Jupyter_Notebooks_and_Datasets_AS_of_16MAY21/Practice/Datasets/kickstarter.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/25 10:17:49 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , blurb, state\n",
      " Schema: _c0, blurb, state\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/randi/Documents/pyspark_udemy/Jupyter+Notebooks+and+Datasets+AS+of+16MAY21/Jupyter_Notebooks_and_Datasets_AS_of_16MAY21/Practice/Datasets/kickstarter.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/25 10:18:39 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , blurb, state\n",
      " Schema: _c0, blurb, state\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/randi/Documents/pyspark_udemy/Jupyter+Notebooks+and+Datasets+AS+of+16MAY21/Jupyter_Notebooks_and_Datasets_AS_of_16MAY21/Practice/Datasets/kickstarter.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/25 10:18:45 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , blurb, state\n",
      " Schema: _c0, blurb, state\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/randi/Documents/pyspark_udemy/Jupyter+Notebooks+and+Datasets+AS+of+16MAY21/Jupyter_Notebooks_and_Datasets_AS_of_16MAY21/Practice/Datasets/kickstarter.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/25 10:19:34 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , blurb, state\n",
      " Schema: _c0, blurb, state\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/randi/Documents/pyspark_udemy/Jupyter+Notebooks+and+Datasets+AS+of+16MAY21/Jupyter_Notebooks_and_Datasets_AS_of_16MAY21/Practice/Datasets/kickstarter.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/25 10:19:36 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , blurb, state\n",
      " Schema: _c0, blurb, state\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/randi/Documents/pyspark_udemy/Jupyter+Notebooks+and+Datasets+AS+of+16MAY21/Jupyter_Notebooks_and_Datasets_AS_of_16MAY21/Practice/Datasets/kickstarter.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/25 10:19:38 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , blurb, state\n",
      " Schema: _c0, blurb, state\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/randi/Documents/pyspark_udemy/Jupyter+Notebooks+and+Datasets+AS+of+16MAY21/Jupyter_Notebooks_and_Datasets_AS_of_16MAY21/Practice/Datasets/kickstarter.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/25 10:19:40 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , blurb, state\n",
      " Schema: _c0, blurb, state\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/randi/Documents/pyspark_udemy/Jupyter+Notebooks+and+Datasets+AS+of+16MAY21/Jupyter_Notebooks_and_Datasets_AS_of_16MAY21/Practice/Datasets/kickstarter.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "\u001b[1mGBTClassifier  Feature Importances\u001b[0m\n",
      "(Scores add up to 1)\n",
      "Lowest score is the least important\n",
      " \n",
      "(20,[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19],[0.0394732237464082,0.05575602830415663,0.053544399595105756,0.045529455631759065,0.04002502470696043,0.05748024244844144,0.06435246237365781,0.062346426013698136,0.03979172346415989,0.04734425652369111,0.052835313176910544,0.03644563142783227,0.04943896044865084,0.044571335875499996,0.057979664882679034,0.05483458743998002,0.04845021591301769,0.05301451796779987,0.046729251326428044,0.0500572787331632])\n",
      "23/01/25 10:19:58 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , blurb, state\n",
      " Schema: _c0, blurb, state\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/randi/Documents/pyspark_udemy/Jupyter+Notebooks+and+Datasets+AS+of+16MAY21/Jupyter_Notebooks_and_Datasets_AS_of_16MAY21/Practice/Datasets/kickstarter.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/25 10:20:01 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , blurb, state\n",
      " Schema: _c0, blurb, state\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/randi/Documents/pyspark_udemy/Jupyter+Notebooks+and+Datasets+AS+of+16MAY21/Jupyter_Notebooks_and_Datasets_AS_of_16MAY21/Practice/Datasets/kickstarter.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/25 10:20:05 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , blurb, state\n",
      " Schema: _c0, blurb, state\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/randi/Documents/pyspark_udemy/Jupyter+Notebooks+and+Datasets+AS+of+16MAY21/Jupyter_Notebooks_and_Datasets_AS_of_16MAY21/Practice/Datasets/kickstarter.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/25 10:20:09 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , blurb, state\n",
      " Schema: _c0, blurb, state\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/randi/Documents/pyspark_udemy/Jupyter+Notebooks+and+Datasets+AS+of+16MAY21/Jupyter_Notebooks_and_Datasets_AS_of_16MAY21/Practice/Datasets/kickstarter.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/25 10:20:13 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , blurb, state\n",
      " Schema: _c0, blurb, state\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/randi/Documents/pyspark_udemy/Jupyter+Notebooks+and+Datasets+AS+of+16MAY21/Jupyter_Notebooks_and_Datasets_AS_of_16MAY21/Practice/Datasets/kickstarter.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/25 10:20:17 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , blurb, state\n",
      " Schema: _c0, blurb, state\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/randi/Documents/pyspark_udemy/Jupyter+Notebooks+and+Datasets+AS+of+16MAY21/Jupyter_Notebooks_and_Datasets_AS_of_16MAY21/Practice/Datasets/kickstarter.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/25 10:20:18 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , blurb, state\n",
      " Schema: _c0, blurb, state\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/randi/Documents/pyspark_udemy/Jupyter+Notebooks+and+Datasets+AS+of+16MAY21/Jupyter_Notebooks_and_Datasets_AS_of_16MAY21/Practice/Datasets/kickstarter.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/25 10:20:21 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , blurb, state\n",
      " Schema: _c0, blurb, state\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/randi/Documents/pyspark_udemy/Jupyter+Notebooks+and+Datasets+AS+of+16MAY21/Jupyter_Notebooks_and_Datasets_AS_of_16MAY21/Practice/Datasets/kickstarter.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/25 10:20:23 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , blurb, state\n",
      " Schema: _c0, blurb, state\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/randi/Documents/pyspark_udemy/Jupyter+Notebooks+and+Datasets+AS+of+16MAY21/Jupyter_Notebooks_and_Datasets_AS_of_16MAY21/Practice/Datasets/kickstarter.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "\u001b[1mDecisionTreeClassifier  Feature Importances\u001b[0m\n",
      "(Scores add up to 1)\n",
      "Lowest score is the least important\n",
      " \n",
      "(20,[0,2,4,5,6,7,8,10,12,15,18,19],[0.008101773017722172,0.22400260258264165,0.012857958649547608,0.3809726925253951,0.04158612397023884,0.030330022537158566,0.012662457049250824,0.10171669755393883,0.017610860848471178,0.013962837799693654,0.14174137698126102,0.014454596484680577])\n",
      "23/01/25 10:20:26 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , blurb, state\n",
      " Schema: _c0, blurb, state\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/randi/Documents/pyspark_udemy/Jupyter+Notebooks+and+Datasets+AS+of+16MAY21/Jupyter_Notebooks_and_Datasets_AS_of_16MAY21/Practice/Datasets/kickstarter.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/25 10:20:28 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , blurb, state\n",
      " Schema: _c0, blurb, state\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/randi/Documents/pyspark_udemy/Jupyter+Notebooks+and+Datasets+AS+of+16MAY21/Jupyter_Notebooks_and_Datasets_AS_of_16MAY21/Practice/Datasets/kickstarter.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1mMultilayerPerceptronClassifier  Weights\u001b[0m\n",
      "\u001b[1mModel Weights: \u001b[0m 923\n",
      "\n",
      "23/01/25 10:20:46 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , blurb, state\n",
      " Schema: _c0, blurb, state\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/randi/Documents/pyspark_udemy/Jupyter+Notebooks+and+Datasets+AS+of+16MAY21/Jupyter_Notebooks_and_Datasets_AS_of_16MAY21/Practice/Datasets/kickstarter.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------+------+\n",
      "|Classifier                    |Result|\n",
      "+------------------------------+------+\n",
      "|LogisticRegression            |52.61 |\n",
      "|OneVsRest                     |52.64 |\n",
      "|LinearSVC                     |52.68 |\n",
      "|NaiveBayes                    |52.31 |\n",
      "|RandomForestClassifier        |52.63 |\n",
      "|GBTClassifier                 |52.44 |\n",
      "|DecisionTreeClassifier        |52.25 |\n",
      "|MultilayerPerceptronClassifier|52.81 |\n",
      "+------------------------------+------+\n",
      "\n",
      "None\n",
      "TFIDFfeaturizedData\n",
      "23/01/25 10:20:49 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , blurb, state\n",
      " Schema: _c0, blurb, state\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/randi/Documents/pyspark_udemy/Jupyter+Notebooks+and+Datasets+AS+of+16MAY21/Jupyter_Notebooks_and_Datasets_AS_of_16MAY21/Practice/Datasets/kickstarter.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/25 10:20:58 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , blurb, state\n",
      " Schema: _c0, blurb, state\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/randi/Documents/pyspark_udemy/Jupyter+Notebooks+and+Datasets+AS+of+16MAY21/Jupyter_Notebooks_and_Datasets_AS_of_16MAY21/Practice/Datasets/kickstarter.csv\n",
      "23/01/25 10:20:59 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , blurb, state\n",
      " Schema: _c0, blurb, state\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/randi/Documents/pyspark_udemy/Jupyter+Notebooks+and+Datasets+AS+of+16MAY21/Jupyter_Notebooks_and_Datasets_AS_of_16MAY21/Practice/Datasets/kickstarter.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/25 10:21:02 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , blurb, state\n",
      " Schema: _c0, blurb, state\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/randi/Documents/pyspark_udemy/Jupyter+Notebooks+and+Datasets+AS+of+16MAY21/Jupyter_Notebooks_and_Datasets_AS_of_16MAY21/Practice/Datasets/kickstarter.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/25 10:21:07 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , blurb, state\n",
      " Schema: _c0, blurb, state\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/randi/Documents/pyspark_udemy/Jupyter+Notebooks+and+Datasets+AS+of+16MAY21/Jupyter_Notebooks_and_Datasets_AS_of_16MAY21/Practice/Datasets/kickstarter.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/25 10:21:10 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , blurb, state\n",
      " Schema: _c0, blurb, state\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/randi/Documents/pyspark_udemy/Jupyter+Notebooks+and+Datasets+AS+of+16MAY21/Jupyter_Notebooks_and_Datasets_AS_of_16MAY21/Practice/Datasets/kickstarter.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/25 10:21:14 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , blurb, state\n",
      " Schema: _c0, blurb, state\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/randi/Documents/pyspark_udemy/Jupyter+Notebooks+and+Datasets+AS+of+16MAY21/Jupyter_Notebooks_and_Datasets_AS_of_16MAY21/Practice/Datasets/kickstarter.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/25 10:21:17 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , blurb, state\n",
      " Schema: _c0, blurb, state\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/randi/Documents/pyspark_udemy/Jupyter+Notebooks+and+Datasets+AS+of+16MAY21/Jupyter_Notebooks_and_Datasets_AS_of_16MAY21/Practice/Datasets/kickstarter.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "\u001b[1mLogisticRegression  Coefficient Matrix\u001b[0m\n",
      "You should compares these relative to eachother\n",
      "Coefficients: \n",
      "DenseMatrix([[-0.03426147,  0.0104125 , -0.0993271 ,  0.00769049, -0.01432663,\n",
      "              -0.14472691, -0.07970345, -0.03973334, -0.03374675, -0.04482459,\n",
      "               0.08229886, -0.0263043 ,  0.00949995,  0.01803923, -0.03383738,\n",
      "              -0.03843415,  0.0111645 , -0.02645515, -0.09042841, -0.02685404]])\n",
      "Intercept: [0.2653436836835483]\n",
      "23/01/25 10:21:20 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , blurb, state\n",
      " Schema: _c0, blurb, state\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/randi/Documents/pyspark_udemy/Jupyter+Notebooks+and+Datasets+AS+of+16MAY21/Jupyter_Notebooks_and_Datasets_AS_of_16MAY21/Practice/Datasets/kickstarter.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/25 10:21:23 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , blurb, state\n",
      " Schema: _c0, blurb, state\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/randi/Documents/pyspark_udemy/Jupyter+Notebooks+and+Datasets+AS+of+16MAY21/Jupyter_Notebooks_and_Datasets_AS_of_16MAY21/Practice/Datasets/kickstarter.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/25 10:21:27 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , blurb, state\n",
      " Schema: _c0, blurb, state\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/randi/Documents/pyspark_udemy/Jupyter+Notebooks+and+Datasets+AS+of+16MAY21/Jupyter_Notebooks_and_Datasets_AS_of_16MAY21/Practice/Datasets/kickstarter.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/25 10:21:35 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , blurb, state\n",
      " Schema: _c0, blurb, state\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/randi/Documents/pyspark_udemy/Jupyter+Notebooks+and+Datasets+AS+of+16MAY21/Jupyter_Notebooks_and_Datasets_AS_of_16MAY21/Practice/Datasets/kickstarter.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/25 10:21:39 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , blurb, state\n",
      " Schema: _c0, blurb, state\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/randi/Documents/pyspark_udemy/Jupyter+Notebooks+and+Datasets+AS+of+16MAY21/Jupyter_Notebooks_and_Datasets_AS_of_16MAY21/Practice/Datasets/kickstarter.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/25 10:21:46 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , blurb, state\n",
      " Schema: _c0, blurb, state\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/randi/Documents/pyspark_udemy/Jupyter+Notebooks+and+Datasets+AS+of+16MAY21/Jupyter_Notebooks_and_Datasets_AS_of_16MAY21/Practice/Datasets/kickstarter.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/25 10:21:48 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , blurb, state\n",
      " Schema: _c0, blurb, state\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/randi/Documents/pyspark_udemy/Jupyter+Notebooks+and+Datasets+AS+of+16MAY21/Jupyter_Notebooks_and_Datasets_AS_of_16MAY21/Practice/Datasets/kickstarter.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/25 10:21:51 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , blurb, state\n",
      " Schema: _c0, blurb, state\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/randi/Documents/pyspark_udemy/Jupyter+Notebooks+and+Datasets+AS+of+16MAY21/Jupyter_Notebooks_and_Datasets_AS_of_16MAY21/Practice/Datasets/kickstarter.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/25 10:21:54 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , blurb, state\n",
      " Schema: _c0, blurb, state\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/randi/Documents/pyspark_udemy/Jupyter+Notebooks+and+Datasets+AS+of+16MAY21/Jupyter_Notebooks_and_Datasets_AS_of_16MAY21/Practice/Datasets/kickstarter.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/25 10:21:57 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , blurb, state\n",
      " Schema: _c0, blurb, state\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/randi/Documents/pyspark_udemy/Jupyter+Notebooks+and+Datasets+AS+of+16MAY21/Jupyter_Notebooks_and_Datasets_AS_of_16MAY21/Practice/Datasets/kickstarter.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "\u001b[1mOneVsRest\u001b[0m\n",
      "\u001b[1mIntercept: \u001b[0m -0.249667082079463 \u001b[1m\n",
      "Coefficients:\u001b[0m [0.03246507546039185,-0.010562629378936851,0.09504097544809874,-0.008163709564499282,0.013423317634517627,0.13879114553387883,0.07618687999509817,0.037850802141731844,0.03206545497447886,0.0425421774131023,-0.07958194429040141,0.024809413973215743,-0.009735426079536903,-0.01801784151214573,0.031963542508819776,0.03638139877485752,-0.011087299579469473,0.02495048488525434,0.08662995339317171,0.025327351921092114]\n",
      "\u001b[1mIntercept: \u001b[0m 0.24966708207946287 \u001b[1m\n",
      "Coefficients:\u001b[0m [-0.03246507546039177,0.010562629378936879,-0.09504097544809872,0.008163709564499317,-0.01342331763451759,-0.1387911455338788,-0.07618687999509821,-0.037850802141731796,-0.032065454974478824,-0.04254217741310234,0.07958194429040147,-0.024809413973215743,0.009735426079536908,0.018017841512145624,-0.03196354250881977,-0.036381398774857535,0.011087299579469459,-0.02495048488525429,-0.08662995339317174,-0.025327351921092076]\n",
      "23/01/25 10:22:01 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , blurb, state\n",
      " Schema: _c0, blurb, state\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/randi/Documents/pyspark_udemy/Jupyter+Notebooks+and+Datasets+AS+of+16MAY21/Jupyter_Notebooks_and_Datasets_AS_of_16MAY21/Practice/Datasets/kickstarter.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/25 10:22:04 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , blurb, state\n",
      " Schema: _c0, blurb, state\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/randi/Documents/pyspark_udemy/Jupyter+Notebooks+and+Datasets+AS+of+16MAY21/Jupyter_Notebooks_and_Datasets_AS_of_16MAY21/Practice/Datasets/kickstarter.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/25 10:22:08 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , blurb, state\n",
      " Schema: _c0, blurb, state\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/randi/Documents/pyspark_udemy/Jupyter+Notebooks+and+Datasets+AS+of+16MAY21/Jupyter_Notebooks_and_Datasets_AS_of_16MAY21/Practice/Datasets/kickstarter.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/25 10:22:15 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , blurb, state\n",
      " Schema: _c0, blurb, state\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/randi/Documents/pyspark_udemy/Jupyter+Notebooks+and+Datasets+AS+of+16MAY21/Jupyter_Notebooks_and_Datasets_AS_of_16MAY21/Practice/Datasets/kickstarter.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/25 10:22:19 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , blurb, state\n",
      " Schema: _c0, blurb, state\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/randi/Documents/pyspark_udemy/Jupyter+Notebooks+and+Datasets+AS+of+16MAY21/Jupyter_Notebooks_and_Datasets_AS_of_16MAY21/Practice/Datasets/kickstarter.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/25 10:22:26 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , blurb, state\n",
      " Schema: _c0, blurb, state\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/randi/Documents/pyspark_udemy/Jupyter+Notebooks+and+Datasets+AS+of+16MAY21/Jupyter_Notebooks_and_Datasets_AS_of_16MAY21/Practice/Datasets/kickstarter.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/25 10:22:28 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , blurb, state\n",
      " Schema: _c0, blurb, state\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/randi/Documents/pyspark_udemy/Jupyter+Notebooks+and+Datasets+AS+of+16MAY21/Jupyter_Notebooks_and_Datasets_AS_of_16MAY21/Practice/Datasets/kickstarter.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "\u001b[1mLinearSVC  Coefficients\u001b[0m\n",
      "You should compares these relative to eachother\n",
      "Coefficients: \n",
      "[-0.11255888623685883,0.03372080286704003,-0.3420218268139701,0.012725114457987647,-0.06243134926406067,-0.4468663606673093,-0.27431277536747495,-0.13902651169869631,-0.13692342752699438,-0.17138184375996438,0.24751725373865135,-0.10293276140055654,0.027355570101081594,0.06253026892231268,-0.126951584124562,-0.1513864571977969,0.03537609001332689,-0.11152456980397185,-0.3135057643100441,-0.11091277437721996]\n",
      "23/01/25 10:22:32 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , blurb, state\n",
      " Schema: _c0, blurb, state\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/randi/Documents/pyspark_udemy/Jupyter+Notebooks+and+Datasets+AS+of+16MAY21/Jupyter_Notebooks_and_Datasets_AS_of_16MAY21/Practice/Datasets/kickstarter.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/25 10:22:35 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , blurb, state\n",
      " Schema: _c0, blurb, state\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/randi/Documents/pyspark_udemy/Jupyter+Notebooks+and+Datasets+AS+of+16MAY21/Jupyter_Notebooks_and_Datasets_AS_of_16MAY21/Practice/Datasets/kickstarter.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/25 10:22:38 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , blurb, state\n",
      " Schema: _c0, blurb, state\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/randi/Documents/pyspark_udemy/Jupyter+Notebooks+and+Datasets+AS+of+16MAY21/Jupyter_Notebooks_and_Datasets_AS_of_16MAY21/Practice/Datasets/kickstarter.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/25 10:22:41 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , blurb, state\n",
      " Schema: _c0, blurb, state\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/randi/Documents/pyspark_udemy/Jupyter+Notebooks+and+Datasets+AS+of+16MAY21/Jupyter_Notebooks_and_Datasets_AS_of_16MAY21/Practice/Datasets/kickstarter.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/25 10:22:44 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , blurb, state\n",
      " Schema: _c0, blurb, state\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/randi/Documents/pyspark_udemy/Jupyter+Notebooks+and+Datasets+AS+of+16MAY21/Jupyter_Notebooks_and_Datasets_AS_of_16MAY21/Practice/Datasets/kickstarter.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/25 10:22:47 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , blurb, state\n",
      " Schema: _c0, blurb, state\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/randi/Documents/pyspark_udemy/Jupyter+Notebooks+and+Datasets+AS+of+16MAY21/Jupyter_Notebooks_and_Datasets_AS_of_16MAY21/Practice/Datasets/kickstarter.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/25 10:22:50 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , blurb, state\n",
      " Schema: _c0, blurb, state\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/randi/Documents/pyspark_udemy/Jupyter+Notebooks+and+Datasets+AS+of+16MAY21/Jupyter_Notebooks_and_Datasets_AS_of_16MAY21/Practice/Datasets/kickstarter.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/25 10:22:53 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , blurb, state\n",
      " Schema: _c0, blurb, state\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/randi/Documents/pyspark_udemy/Jupyter+Notebooks+and+Datasets+AS+of+16MAY21/Jupyter_Notebooks_and_Datasets_AS_of_16MAY21/Practice/Datasets/kickstarter.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/25 10:22:57 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , blurb, state\n",
      " Schema: _c0, blurb, state\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/randi/Documents/pyspark_udemy/Jupyter+Notebooks+and+Datasets+AS+of+16MAY21/Jupyter_Notebooks_and_Datasets_AS_of_16MAY21/Practice/Datasets/kickstarter.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/25 10:23:02 WARN DAGScheduler: Broadcasting large task binary with size 1058.7 KiB\n",
      "23/01/25 10:23:02 WARN DAGScheduler: Broadcasting large task binary with size 1639.0 KiB\n",
      "23/01/25 10:23:03 WARN DAGScheduler: Broadcasting large task binary with size 1229.1 KiB\n",
      "23/01/25 10:23:03 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , blurb, state\n",
      " Schema: _c0, blurb, state\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/randi/Documents/pyspark_udemy/Jupyter+Notebooks+and+Datasets+AS+of+16MAY21/Jupyter_Notebooks_and_Datasets_AS_of_16MAY21/Practice/Datasets/kickstarter.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/25 10:23:08 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , blurb, state\n",
      " Schema: _c0, blurb, state\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/randi/Documents/pyspark_udemy/Jupyter+Notebooks+and+Datasets+AS+of+16MAY21/Jupyter_Notebooks_and_Datasets_AS_of_16MAY21/Practice/Datasets/kickstarter.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/25 10:23:12 WARN DAGScheduler: Broadcasting large task binary with size 1035.4 KiB\n",
      "23/01/25 10:23:13 WARN DAGScheduler: Broadcasting large task binary with size 1602.2 KiB\n",
      "23/01/25 10:23:14 WARN DAGScheduler: Broadcasting large task binary with size 1208.1 KiB\n",
      "23/01/25 10:23:14 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , blurb, state\n",
      " Schema: _c0, blurb, state\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/randi/Documents/pyspark_udemy/Jupyter+Notebooks+and+Datasets+AS+of+16MAY21/Jupyter_Notebooks_and_Datasets_AS_of_16MAY21/Practice/Datasets/kickstarter.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/25 10:23:15 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , blurb, state\n",
      " Schema: _c0, blurb, state\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/randi/Documents/pyspark_udemy/Jupyter+Notebooks+and+Datasets+AS+of+16MAY21/Jupyter_Notebooks_and_Datasets_AS_of_16MAY21/Practice/Datasets/kickstarter.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/25 10:23:18 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , blurb, state\n",
      " Schema: _c0, blurb, state\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/randi/Documents/pyspark_udemy/Jupyter+Notebooks+and+Datasets+AS+of+16MAY21/Jupyter_Notebooks_and_Datasets_AS_of_16MAY21/Practice/Datasets/kickstarter.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/25 10:23:20 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , blurb, state\n",
      " Schema: _c0, blurb, state\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/randi/Documents/pyspark_udemy/Jupyter+Notebooks+and+Datasets+AS+of+16MAY21/Jupyter_Notebooks_and_Datasets_AS_of_16MAY21/Practice/Datasets/kickstarter.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/25 10:23:24 WARN DAGScheduler: Broadcasting large task binary with size 1114.4 KiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/25 10:23:25 WARN DAGScheduler: Broadcasting large task binary with size 1797.2 KiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "\u001b[1mRandomForestClassifier  Feature Importances\u001b[0m\n",
      "(Scores add up to 1)\n",
      "Lowest score is the least important\n",
      " \n",
      "(20,[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19],[0.045816234845427864,0.04098253540308568,0.06687495617517647,0.04699095348664945,0.03969000479288093,0.10167573363505063,0.05051365472398783,0.04980753930155541,0.03891218894711769,0.04029211889435241,0.0698382097608313,0.043292329886329764,0.04502876834610426,0.04635343756553399,0.04331428754526033,0.043463097677385445,0.039649284821531815,0.043139437864290066,0.06192914072346034,0.042436085603988295])\n",
      "23/01/25 10:23:27 WARN DAGScheduler: Broadcasting large task binary with size 1344.7 KiB\n",
      "23/01/25 10:23:27 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , blurb, state\n",
      " Schema: _c0, blurb, state\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/randi/Documents/pyspark_udemy/Jupyter+Notebooks+and+Datasets+AS+of+16MAY21/Jupyter_Notebooks_and_Datasets_AS_of_16MAY21/Practice/Datasets/kickstarter.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/25 10:23:29 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , blurb, state\n",
      " Schema: _c0, blurb, state\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/randi/Documents/pyspark_udemy/Jupyter+Notebooks+and+Datasets+AS+of+16MAY21/Jupyter_Notebooks_and_Datasets_AS_of_16MAY21/Practice/Datasets/kickstarter.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/25 10:23:35 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , blurb, state\n",
      " Schema: _c0, blurb, state\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/randi/Documents/pyspark_udemy/Jupyter+Notebooks+and+Datasets+AS+of+16MAY21/Jupyter_Notebooks_and_Datasets_AS_of_16MAY21/Practice/Datasets/kickstarter.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/25 10:24:26 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , blurb, state\n",
      " Schema: _c0, blurb, state\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/randi/Documents/pyspark_udemy/Jupyter+Notebooks+and+Datasets+AS+of+16MAY21/Jupyter_Notebooks_and_Datasets_AS_of_16MAY21/Practice/Datasets/kickstarter.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/25 10:24:33 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , blurb, state\n",
      " Schema: _c0, blurb, state\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/randi/Documents/pyspark_udemy/Jupyter+Notebooks+and+Datasets+AS+of+16MAY21/Jupyter_Notebooks_and_Datasets_AS_of_16MAY21/Practice/Datasets/kickstarter.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/25 10:25:27 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , blurb, state\n",
      " Schema: _c0, blurb, state\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/randi/Documents/pyspark_udemy/Jupyter+Notebooks+and+Datasets+AS+of+16MAY21/Jupyter_Notebooks_and_Datasets_AS_of_16MAY21/Practice/Datasets/kickstarter.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/25 10:25:28 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , blurb, state\n",
      " Schema: _c0, blurb, state\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/randi/Documents/pyspark_udemy/Jupyter+Notebooks+and+Datasets+AS+of+16MAY21/Jupyter_Notebooks_and_Datasets_AS_of_16MAY21/Practice/Datasets/kickstarter.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/25 10:25:31 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , blurb, state\n",
      " Schema: _c0, blurb, state\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/randi/Documents/pyspark_udemy/Jupyter+Notebooks+and+Datasets+AS+of+16MAY21/Jupyter_Notebooks_and_Datasets_AS_of_16MAY21/Practice/Datasets/kickstarter.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/25 10:25:34 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , blurb, state\n",
      " Schema: _c0, blurb, state\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/randi/Documents/pyspark_udemy/Jupyter+Notebooks+and+Datasets+AS+of+16MAY21/Jupyter_Notebooks_and_Datasets_AS_of_16MAY21/Practice/Datasets/kickstarter.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "\u001b[1mGBTClassifier  Feature Importances\u001b[0m\n",
      "(Scores add up to 1)\n",
      "Lowest score is the least important\n",
      " \n",
      "(20,[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19],[0.0394732237464082,0.05575602830415663,0.053544399595105756,0.045529455631759065,0.04002502470696043,0.05748024244844144,0.06435246237365781,0.062346426013698136,0.03979172346415989,0.04734425652369111,0.052835313176910544,0.03644563142783227,0.04943896044865084,0.044571335875499996,0.057979664882679034,0.05483458743998002,0.04845021591301769,0.05301451796779987,0.046729251326428044,0.0500572787331632])\n",
      "23/01/25 10:25:54 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , blurb, state\n",
      " Schema: _c0, blurb, state\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/randi/Documents/pyspark_udemy/Jupyter+Notebooks+and+Datasets+AS+of+16MAY21/Jupyter_Notebooks_and_Datasets_AS_of_16MAY21/Practice/Datasets/kickstarter.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/25 10:25:57 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , blurb, state\n",
      " Schema: _c0, blurb, state\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/randi/Documents/pyspark_udemy/Jupyter+Notebooks+and+Datasets+AS+of+16MAY21/Jupyter_Notebooks_and_Datasets_AS_of_16MAY21/Practice/Datasets/kickstarter.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/25 10:26:02 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , blurb, state\n",
      " Schema: _c0, blurb, state\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/randi/Documents/pyspark_udemy/Jupyter+Notebooks+and+Datasets+AS+of+16MAY21/Jupyter_Notebooks_and_Datasets_AS_of_16MAY21/Practice/Datasets/kickstarter.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/25 10:26:07 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , blurb, state\n",
      " Schema: _c0, blurb, state\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/randi/Documents/pyspark_udemy/Jupyter+Notebooks+and+Datasets+AS+of+16MAY21/Jupyter_Notebooks_and_Datasets_AS_of_16MAY21/Practice/Datasets/kickstarter.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/25 10:26:12 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , blurb, state\n",
      " Schema: _c0, blurb, state\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/randi/Documents/pyspark_udemy/Jupyter+Notebooks+and+Datasets+AS+of+16MAY21/Jupyter_Notebooks_and_Datasets_AS_of_16MAY21/Practice/Datasets/kickstarter.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/25 10:26:17 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , blurb, state\n",
      " Schema: _c0, blurb, state\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/randi/Documents/pyspark_udemy/Jupyter+Notebooks+and+Datasets+AS+of+16MAY21/Jupyter_Notebooks_and_Datasets_AS_of_16MAY21/Practice/Datasets/kickstarter.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/25 10:26:18 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , blurb, state\n",
      " Schema: _c0, blurb, state\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/randi/Documents/pyspark_udemy/Jupyter+Notebooks+and+Datasets+AS+of+16MAY21/Jupyter_Notebooks_and_Datasets_AS_of_16MAY21/Practice/Datasets/kickstarter.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/25 10:26:21 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , blurb, state\n",
      " Schema: _c0, blurb, state\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/randi/Documents/pyspark_udemy/Jupyter+Notebooks+and+Datasets+AS+of+16MAY21/Jupyter_Notebooks_and_Datasets_AS_of_16MAY21/Practice/Datasets/kickstarter.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/25 10:26:25 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , blurb, state\n",
      " Schema: _c0, blurb, state\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/randi/Documents/pyspark_udemy/Jupyter+Notebooks+and+Datasets+AS+of+16MAY21/Jupyter_Notebooks_and_Datasets_AS_of_16MAY21/Practice/Datasets/kickstarter.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "\u001b[1mDecisionTreeClassifier  Feature Importances\u001b[0m\n",
      "(Scores add up to 1)\n",
      "Lowest score is the least important\n",
      " \n",
      "(20,[0,2,4,5,6,7,8,10,12,15,18,19],[0.008101773017722172,0.22400260258264165,0.012857958649547608,0.3809726925253951,0.04158612397023884,0.030330022537158566,0.012662457049250824,0.10171669755393883,0.017610860848471178,0.013962837799693654,0.14174137698126102,0.014454596484680577])\n",
      "23/01/25 10:26:28 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , blurb, state\n",
      " Schema: _c0, blurb, state\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/randi/Documents/pyspark_udemy/Jupyter+Notebooks+and+Datasets+AS+of+16MAY21/Jupyter_Notebooks_and_Datasets_AS_of_16MAY21/Practice/Datasets/kickstarter.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/25 10:26:31 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , blurb, state\n",
      " Schema: _c0, blurb, state\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/randi/Documents/pyspark_udemy/Jupyter+Notebooks+and+Datasets+AS+of+16MAY21/Jupyter_Notebooks_and_Datasets_AS_of_16MAY21/Practice/Datasets/kickstarter.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1mMultilayerPerceptronClassifier  Weights\u001b[0m\n",
      "\u001b[1mModel Weights: \u001b[0m 923\n",
      "\n",
      "23/01/25 10:26:51 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , blurb, state\n",
      " Schema: _c0, blurb, state\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/randi/Documents/pyspark_udemy/Jupyter+Notebooks+and+Datasets+AS+of+16MAY21/Jupyter_Notebooks_and_Datasets_AS_of_16MAY21/Practice/Datasets/kickstarter.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------+------+\n",
      "|Classifier                    |Result|\n",
      "+------------------------------+------+\n",
      "|LogisticRegression            |52.61 |\n",
      "|OneVsRest                     |52.64 |\n",
      "|LinearSVC                     |52.68 |\n",
      "|NaiveBayes                    |52.14 |\n",
      "|RandomForestClassifier        |52.63 |\n",
      "|GBTClassifier                 |52.44 |\n",
      "|DecisionTreeClassifier        |52.25 |\n",
      "|MultilayerPerceptronClassifier|52.78 |\n",
      "+------------------------------+------+\n",
      "\n",
      "None\n",
      "W2VfeaturizedData\n",
      "23/01/25 10:26:55 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , blurb, state\n",
      " Schema: _c0, blurb, state\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/randi/Documents/pyspark_udemy/Jupyter+Notebooks+and+Datasets+AS+of+16MAY21/Jupyter_Notebooks_and_Datasets_AS_of_16MAY21/Practice/Datasets/kickstarter.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/25 10:27:01 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , blurb, state\n",
      " Schema: _c0, blurb, state\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/randi/Documents/pyspark_udemy/Jupyter+Notebooks+and+Datasets+AS+of+16MAY21/Jupyter_Notebooks_and_Datasets_AS_of_16MAY21/Practice/Datasets/kickstarter.csv\n",
      "23/01/25 10:27:02 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , blurb, state\n",
      " Schema: _c0, blurb, state\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/randi/Documents/pyspark_udemy/Jupyter+Notebooks+and+Datasets+AS+of+16MAY21/Jupyter_Notebooks_and_Datasets_AS_of_16MAY21/Practice/Datasets/kickstarter.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/25 10:27:05 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , blurb, state\n",
      " Schema: _c0, blurb, state\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/randi/Documents/pyspark_udemy/Jupyter+Notebooks+and+Datasets+AS+of+16MAY21/Jupyter_Notebooks_and_Datasets_AS_of_16MAY21/Practice/Datasets/kickstarter.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/25 10:27:09 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , blurb, state\n",
      " Schema: _c0, blurb, state\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/randi/Documents/pyspark_udemy/Jupyter+Notebooks+and+Datasets+AS+of+16MAY21/Jupyter_Notebooks_and_Datasets_AS_of_16MAY21/Practice/Datasets/kickstarter.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/25 10:27:13 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , blurb, state\n",
      " Schema: _c0, blurb, state\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/randi/Documents/pyspark_udemy/Jupyter+Notebooks+and+Datasets+AS+of+16MAY21/Jupyter_Notebooks_and_Datasets_AS_of_16MAY21/Practice/Datasets/kickstarter.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/25 10:27:17 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , blurb, state\n",
      " Schema: _c0, blurb, state\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/randi/Documents/pyspark_udemy/Jupyter+Notebooks+and+Datasets+AS+of+16MAY21/Jupyter_Notebooks_and_Datasets_AS_of_16MAY21/Practice/Datasets/kickstarter.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/25 10:27:19 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , blurb, state\n",
      " Schema: _c0, blurb, state\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/randi/Documents/pyspark_udemy/Jupyter+Notebooks+and+Datasets+AS+of+16MAY21/Jupyter_Notebooks_and_Datasets_AS_of_16MAY21/Practice/Datasets/kickstarter.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "\u001b[1mLogisticRegression  Coefficient Matrix\u001b[0m\n",
      "You should compares these relative to eachother\n",
      "Coefficients: \n",
      "DenseMatrix([[ 1.30810472, -1.80951787,  1.50797121]])\n",
      "\n",
      "Intercept: [-0.6155394936241041]\n",
      "23/01/25 10:27:23 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , blurb, state\n",
      " Schema: _c0, blurb, state\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/randi/Documents/pyspark_udemy/Jupyter+Notebooks+and+Datasets+AS+of+16MAY21/Jupyter_Notebooks_and_Datasets_AS_of_16MAY21/Practice/Datasets/kickstarter.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/25 10:27:25 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , blurb, state\n",
      " Schema: _c0, blurb, state\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/randi/Documents/pyspark_udemy/Jupyter+Notebooks+and+Datasets+AS+of+16MAY21/Jupyter_Notebooks_and_Datasets_AS_of_16MAY21/Practice/Datasets/kickstarter.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/25 10:27:30 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , blurb, state\n",
      " Schema: _c0, blurb, state\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/randi/Documents/pyspark_udemy/Jupyter+Notebooks+and+Datasets+AS+of+16MAY21/Jupyter_Notebooks_and_Datasets_AS_of_16MAY21/Practice/Datasets/kickstarter.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/25 10:27:38 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , blurb, state\n",
      " Schema: _c0, blurb, state\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/randi/Documents/pyspark_udemy/Jupyter+Notebooks+and+Datasets+AS+of+16MAY21/Jupyter_Notebooks_and_Datasets_AS_of_16MAY21/Practice/Datasets/kickstarter.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/25 10:27:42 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , blurb, state\n",
      " Schema: _c0, blurb, state\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/randi/Documents/pyspark_udemy/Jupyter+Notebooks+and+Datasets+AS+of+16MAY21/Jupyter_Notebooks_and_Datasets_AS_of_16MAY21/Practice/Datasets/kickstarter.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/25 10:27:48 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , blurb, state\n",
      " Schema: _c0, blurb, state\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/randi/Documents/pyspark_udemy/Jupyter+Notebooks+and+Datasets+AS+of+16MAY21/Jupyter_Notebooks_and_Datasets_AS_of_16MAY21/Practice/Datasets/kickstarter.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/25 10:27:50 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , blurb, state\n",
      " Schema: _c0, blurb, state\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/randi/Documents/pyspark_udemy/Jupyter+Notebooks+and+Datasets+AS+of+16MAY21/Jupyter_Notebooks_and_Datasets_AS_of_16MAY21/Practice/Datasets/kickstarter.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/25 10:27:53 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , blurb, state\n",
      " Schema: _c0, blurb, state\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/randi/Documents/pyspark_udemy/Jupyter+Notebooks+and+Datasets+AS+of+16MAY21/Jupyter_Notebooks_and_Datasets_AS_of_16MAY21/Practice/Datasets/kickstarter.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/25 10:27:56 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , blurb, state\n",
      " Schema: _c0, blurb, state\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/randi/Documents/pyspark_udemy/Jupyter+Notebooks+and+Datasets+AS+of+16MAY21/Jupyter_Notebooks_and_Datasets_AS_of_16MAY21/Practice/Datasets/kickstarter.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/25 10:27:59 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , blurb, state\n",
      " Schema: _c0, blurb, state\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/randi/Documents/pyspark_udemy/Jupyter+Notebooks+and+Datasets+AS+of+16MAY21/Jupyter_Notebooks_and_Datasets_AS_of_16MAY21/Practice/Datasets/kickstarter.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "\u001b[1mOneVsRest\u001b[0m\n",
      "\u001b[1mIntercept: \u001b[0m 0.5646789302812425 \u001b[1m\n",
      "Coefficients:\u001b[0m [-1.2887835859435484,1.6614773116404817,-1.3073018508975234]\n",
      "\u001b[1mIntercept: \u001b[0m -0.5646789302812423 \u001b[1m\n",
      "Coefficients:\u001b[0m [1.2887835859435322,-1.6614773116405228,1.3073018508975758]\n",
      "23/01/25 10:28:03 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , blurb, state\n",
      " Schema: _c0, blurb, state\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/randi/Documents/pyspark_udemy/Jupyter+Notebooks+and+Datasets+AS+of+16MAY21/Jupyter_Notebooks_and_Datasets_AS_of_16MAY21/Practice/Datasets/kickstarter.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/25 10:28:07 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , blurb, state\n",
      " Schema: _c0, blurb, state\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/randi/Documents/pyspark_udemy/Jupyter+Notebooks+and+Datasets+AS+of+16MAY21/Jupyter_Notebooks_and_Datasets_AS_of_16MAY21/Practice/Datasets/kickstarter.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/25 10:28:10 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , blurb, state\n",
      " Schema: _c0, blurb, state\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/randi/Documents/pyspark_udemy/Jupyter+Notebooks+and+Datasets+AS+of+16MAY21/Jupyter_Notebooks_and_Datasets_AS_of_16MAY21/Practice/Datasets/kickstarter.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/25 10:28:18 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , blurb, state\n",
      " Schema: _c0, blurb, state\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/randi/Documents/pyspark_udemy/Jupyter+Notebooks+and+Datasets+AS+of+16MAY21/Jupyter_Notebooks_and_Datasets_AS_of_16MAY21/Practice/Datasets/kickstarter.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/25 10:28:21 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , blurb, state\n",
      " Schema: _c0, blurb, state\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/randi/Documents/pyspark_udemy/Jupyter+Notebooks+and+Datasets+AS+of+16MAY21/Jupyter_Notebooks_and_Datasets_AS_of_16MAY21/Practice/Datasets/kickstarter.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/25 10:28:28 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , blurb, state\n",
      " Schema: _c0, blurb, state\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/randi/Documents/pyspark_udemy/Jupyter+Notebooks+and+Datasets+AS+of+16MAY21/Jupyter_Notebooks_and_Datasets_AS_of_16MAY21/Practice/Datasets/kickstarter.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/25 10:28:30 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , blurb, state\n",
      " Schema: _c0, blurb, state\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/randi/Documents/pyspark_udemy/Jupyter+Notebooks+and+Datasets+AS+of+16MAY21/Jupyter_Notebooks_and_Datasets_AS_of_16MAY21/Practice/Datasets/kickstarter.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "\u001b[1mLinearSVC  Coefficients\u001b[0m\n",
      "You should compares these relative to eachother\n",
      "Coefficients: \n",
      "[4.194140194047077,-4.951400400584057,1.6072900905457346]\n",
      "23/01/25 10:28:34 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , blurb, state\n",
      " Schema: _c0, blurb, state\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/randi/Documents/pyspark_udemy/Jupyter+Notebooks+and+Datasets+AS+of+16MAY21/Jupyter_Notebooks_and_Datasets_AS_of_16MAY21/Practice/Datasets/kickstarter.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/25 10:28:37 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , blurb, state\n",
      " Schema: _c0, blurb, state\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/randi/Documents/pyspark_udemy/Jupyter+Notebooks+and+Datasets+AS+of+16MAY21/Jupyter_Notebooks_and_Datasets_AS_of_16MAY21/Practice/Datasets/kickstarter.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/25 10:28:40 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , blurb, state\n",
      " Schema: _c0, blurb, state\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/randi/Documents/pyspark_udemy/Jupyter+Notebooks+and+Datasets+AS+of+16MAY21/Jupyter_Notebooks_and_Datasets_AS_of_16MAY21/Practice/Datasets/kickstarter.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/25 10:28:43 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , blurb, state\n",
      " Schema: _c0, blurb, state\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/randi/Documents/pyspark_udemy/Jupyter+Notebooks+and+Datasets+AS+of+16MAY21/Jupyter_Notebooks_and_Datasets_AS_of_16MAY21/Practice/Datasets/kickstarter.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/25 10:28:46 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , blurb, state\n",
      " Schema: _c0, blurb, state\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/randi/Documents/pyspark_udemy/Jupyter+Notebooks+and+Datasets+AS+of+16MAY21/Jupyter_Notebooks_and_Datasets_AS_of_16MAY21/Practice/Datasets/kickstarter.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/25 10:28:49 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , blurb, state\n",
      " Schema: _c0, blurb, state\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/randi/Documents/pyspark_udemy/Jupyter+Notebooks+and+Datasets+AS+of+16MAY21/Jupyter_Notebooks_and_Datasets_AS_of_16MAY21/Practice/Datasets/kickstarter.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/25 10:28:52 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , blurb, state\n",
      " Schema: _c0, blurb, state\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/randi/Documents/pyspark_udemy/Jupyter+Notebooks+and+Datasets+AS+of+16MAY21/Jupyter_Notebooks_and_Datasets_AS_of_16MAY21/Practice/Datasets/kickstarter.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/25 10:28:55 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , blurb, state\n",
      " Schema: _c0, blurb, state\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/randi/Documents/pyspark_udemy/Jupyter+Notebooks+and+Datasets+AS+of+16MAY21/Jupyter_Notebooks_and_Datasets_AS_of_16MAY21/Practice/Datasets/kickstarter.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/25 10:28:59 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , blurb, state\n",
      " Schema: _c0, blurb, state\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/randi/Documents/pyspark_udemy/Jupyter+Notebooks+and+Datasets+AS+of+16MAY21/Jupyter_Notebooks_and_Datasets_AS_of_16MAY21/Practice/Datasets/kickstarter.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/25 10:29:04 WARN DAGScheduler: Broadcasting large task binary with size 1287.8 KiB\n",
      "23/01/25 10:29:05 WARN DAGScheduler: Broadcasting large task binary with size 2.1 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/25 10:29:06 WARN DAGScheduler: Broadcasting large task binary with size 1422.4 KiB\n",
      "23/01/25 10:29:06 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , blurb, state\n",
      " Schema: _c0, blurb, state\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/randi/Documents/pyspark_udemy/Jupyter+Notebooks+and+Datasets+AS+of+16MAY21/Jupyter_Notebooks_and_Datasets_AS_of_16MAY21/Practice/Datasets/kickstarter.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/25 10:29:10 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , blurb, state\n",
      " Schema: _c0, blurb, state\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/randi/Documents/pyspark_udemy/Jupyter+Notebooks+and+Datasets+AS+of+16MAY21/Jupyter_Notebooks_and_Datasets_AS_of_16MAY21/Practice/Datasets/kickstarter.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/25 10:29:15 WARN DAGScheduler: Broadcasting large task binary with size 1253.5 KiB\n",
      "23/01/25 10:29:16 WARN DAGScheduler: Broadcasting large task binary with size 2.1 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/25 10:29:17 WARN DAGScheduler: Broadcasting large task binary with size 1359.8 KiB\n",
      "23/01/25 10:29:18 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , blurb, state\n",
      " Schema: _c0, blurb, state\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/randi/Documents/pyspark_udemy/Jupyter+Notebooks+and+Datasets+AS+of+16MAY21/Jupyter_Notebooks_and_Datasets_AS_of_16MAY21/Practice/Datasets/kickstarter.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/25 10:29:19 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , blurb, state\n",
      " Schema: _c0, blurb, state\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/randi/Documents/pyspark_udemy/Jupyter+Notebooks+and+Datasets+AS+of+16MAY21/Jupyter_Notebooks_and_Datasets_AS_of_16MAY21/Practice/Datasets/kickstarter.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/25 10:29:21 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , blurb, state\n",
      " Schema: _c0, blurb, state\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/randi/Documents/pyspark_udemy/Jupyter+Notebooks+and+Datasets+AS+of+16MAY21/Jupyter_Notebooks_and_Datasets_AS_of_16MAY21/Practice/Datasets/kickstarter.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/25 10:29:24 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , blurb, state\n",
      " Schema: _c0, blurb, state\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/randi/Documents/pyspark_udemy/Jupyter+Notebooks+and+Datasets+AS+of+16MAY21/Jupyter_Notebooks_and_Datasets_AS_of_16MAY21/Practice/Datasets/kickstarter.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "\u001b[1mRandomForestClassifier  Feature Importances\u001b[0m\n",
      "(Scores add up to 1)\n",
      "Lowest score is the least important\n",
      " \n",
      "(3,[0,1,2],[0.38750004546505934,0.528986547761474,0.08351340677346668])\n",
      "23/01/25 10:29:27 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , blurb, state\n",
      " Schema: _c0, blurb, state\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/randi/Documents/pyspark_udemy/Jupyter+Notebooks+and+Datasets+AS+of+16MAY21/Jupyter_Notebooks_and_Datasets_AS_of_16MAY21/Practice/Datasets/kickstarter.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/25 10:29:30 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , blurb, state\n",
      " Schema: _c0, blurb, state\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/randi/Documents/pyspark_udemy/Jupyter+Notebooks+and+Datasets+AS+of+16MAY21/Jupyter_Notebooks_and_Datasets_AS_of_16MAY21/Practice/Datasets/kickstarter.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/25 10:29:36 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , blurb, state\n",
      " Schema: _c0, blurb, state\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/randi/Documents/pyspark_udemy/Jupyter+Notebooks+and+Datasets+AS+of+16MAY21/Jupyter_Notebooks_and_Datasets_AS_of_16MAY21/Practice/Datasets/kickstarter.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/25 10:30:32 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , blurb, state\n",
      " Schema: _c0, blurb, state\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/randi/Documents/pyspark_udemy/Jupyter+Notebooks+and+Datasets+AS+of+16MAY21/Jupyter_Notebooks_and_Datasets_AS_of_16MAY21/Practice/Datasets/kickstarter.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/25 10:30:38 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , blurb, state\n",
      " Schema: _c0, blurb, state\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/randi/Documents/pyspark_udemy/Jupyter+Notebooks+and+Datasets+AS+of+16MAY21/Jupyter_Notebooks_and_Datasets_AS_of_16MAY21/Practice/Datasets/kickstarter.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/25 10:31:34 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , blurb, state\n",
      " Schema: _c0, blurb, state\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/randi/Documents/pyspark_udemy/Jupyter+Notebooks+and+Datasets+AS+of+16MAY21/Jupyter_Notebooks_and_Datasets_AS_of_16MAY21/Practice/Datasets/kickstarter.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/25 10:31:35 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , blurb, state\n",
      " Schema: _c0, blurb, state\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/randi/Documents/pyspark_udemy/Jupyter+Notebooks+and+Datasets+AS+of+16MAY21/Jupyter_Notebooks_and_Datasets_AS_of_16MAY21/Practice/Datasets/kickstarter.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/25 10:31:38 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , blurb, state\n",
      " Schema: _c0, blurb, state\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/randi/Documents/pyspark_udemy/Jupyter+Notebooks+and+Datasets+AS+of+16MAY21/Jupyter_Notebooks_and_Datasets_AS_of_16MAY21/Practice/Datasets/kickstarter.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/25 10:31:40 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , blurb, state\n",
      " Schema: _c0, blurb, state\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/randi/Documents/pyspark_udemy/Jupyter+Notebooks+and+Datasets+AS+of+16MAY21/Jupyter_Notebooks_and_Datasets_AS_of_16MAY21/Practice/Datasets/kickstarter.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "\u001b[1mGBTClassifier  Feature Importances\u001b[0m\n",
      "(Scores add up to 1)\n",
      "Lowest score is the least important\n",
      " \n",
      "(3,[0,1,2],[0.3909004897046106,0.4124138706995312,0.19668563959585816])\n",
      "23/01/25 10:31:46 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , blurb, state\n",
      " Schema: _c0, blurb, state\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/randi/Documents/pyspark_udemy/Jupyter+Notebooks+and+Datasets+AS+of+16MAY21/Jupyter_Notebooks_and_Datasets_AS_of_16MAY21/Practice/Datasets/kickstarter.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/25 10:31:48 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , blurb, state\n",
      " Schema: _c0, blurb, state\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/randi/Documents/pyspark_udemy/Jupyter+Notebooks+and+Datasets+AS+of+16MAY21/Jupyter_Notebooks_and_Datasets_AS_of_16MAY21/Practice/Datasets/kickstarter.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/25 10:31:52 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , blurb, state\n",
      " Schema: _c0, blurb, state\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/randi/Documents/pyspark_udemy/Jupyter+Notebooks+and+Datasets+AS+of+16MAY21/Jupyter_Notebooks_and_Datasets_AS_of_16MAY21/Practice/Datasets/kickstarter.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/25 10:31:57 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , blurb, state\n",
      " Schema: _c0, blurb, state\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/randi/Documents/pyspark_udemy/Jupyter+Notebooks+and+Datasets+AS+of+16MAY21/Jupyter_Notebooks_and_Datasets_AS_of_16MAY21/Practice/Datasets/kickstarter.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/25 10:32:01 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , blurb, state\n",
      " Schema: _c0, blurb, state\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/randi/Documents/pyspark_udemy/Jupyter+Notebooks+and+Datasets+AS+of+16MAY21/Jupyter_Notebooks_and_Datasets_AS_of_16MAY21/Practice/Datasets/kickstarter.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/25 10:32:05 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , blurb, state\n",
      " Schema: _c0, blurb, state\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/randi/Documents/pyspark_udemy/Jupyter+Notebooks+and+Datasets+AS+of+16MAY21/Jupyter_Notebooks_and_Datasets_AS_of_16MAY21/Practice/Datasets/kickstarter.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/25 10:32:07 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , blurb, state\n",
      " Schema: _c0, blurb, state\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/randi/Documents/pyspark_udemy/Jupyter+Notebooks+and+Datasets+AS+of+16MAY21/Jupyter_Notebooks_and_Datasets_AS_of_16MAY21/Practice/Datasets/kickstarter.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/25 10:32:09 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , blurb, state\n",
      " Schema: _c0, blurb, state\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/randi/Documents/pyspark_udemy/Jupyter+Notebooks+and+Datasets+AS+of+16MAY21/Jupyter_Notebooks_and_Datasets_AS_of_16MAY21/Practice/Datasets/kickstarter.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/25 10:32:12 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , blurb, state\n",
      " Schema: _c0, blurb, state\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/randi/Documents/pyspark_udemy/Jupyter+Notebooks+and+Datasets+AS+of+16MAY21/Jupyter_Notebooks_and_Datasets_AS_of_16MAY21/Practice/Datasets/kickstarter.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "\u001b[1mDecisionTreeClassifier  Feature Importances\u001b[0m\n",
      "(Scores add up to 1)\n",
      "Lowest score is the least important\n",
      " \n",
      "(3,[0,1,2],[0.3912169716714286,0.5538695637905796,0.05491346453799188])\n",
      "23/01/25 10:32:14 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , blurb, state\n",
      " Schema: _c0, blurb, state\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/randi/Documents/pyspark_udemy/Jupyter+Notebooks+and+Datasets+AS+of+16MAY21/Jupyter_Notebooks_and_Datasets_AS_of_16MAY21/Practice/Datasets/kickstarter.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/25 10:32:17 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , blurb, state\n",
      " Schema: _c0, blurb, state\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/randi/Documents/pyspark_udemy/Jupyter+Notebooks+and+Datasets+AS+of+16MAY21/Jupyter_Notebooks_and_Datasets_AS_of_16MAY21/Practice/Datasets/kickstarter.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1mMultilayerPerceptronClassifier  Weights\u001b[0m\n",
      "\u001b[1mModel Weights: \u001b[0m 39\n",
      "\n",
      "23/01/25 10:32:28 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , blurb, state\n",
      " Schema: _c0, blurb, state\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/randi/Documents/pyspark_udemy/Jupyter+Notebooks+and+Datasets+AS+of+16MAY21/Jupyter_Notebooks_and_Datasets_AS_of_16MAY21/Practice/Datasets/kickstarter.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------+------+\n",
      "|Classifier                    |Result|\n",
      "+------------------------------+------+\n",
      "|LogisticRegression            |55.33 |\n",
      "|OneVsRest                     |55.37 |\n",
      "|LinearSVC                     |54.48 |\n",
      "|NaiveBayes                    |50.42 |\n",
      "|RandomForestClassifier        |57.19 |\n",
      "|GBTClassifier                 |57.12 |\n",
      "|DecisionTreeClassifier        |56.95 |\n",
      "|MultilayerPerceptronClassifier|57.08 |\n",
      "+------------------------------+------+\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "for featureDF in featureDF_list:\n",
    "    print(featureDF.name)\n",
    "    train, test = featureDF.randomSplit([0.7,0.3], seed=11)\n",
    "\n",
    "    features = featureDF.select(['features']).collect()\n",
    "    class_count = featureDF.select(countDistinct(\"label\")).collect()\n",
    "    classes = class_count[0][0]\n",
    "\n",
    "    columns = ['Classifier','Result']\n",
    "    vals = [(\"Place Holder\", \"N/A\")]\n",
    "    results = spark.createDataFrame(vals, columns)\n",
    "\n",
    "    for classifier in classifiers:\n",
    "        new_result = ClassTrainEval(classifier, features, classes, train, test)\n",
    "        results = results.union(new_result)\n",
    "    results = results.where(\"Classifier!='Place Holder'\")\n",
    "    print(results.show(truncate=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/25 10:44:09 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , blurb, state\n",
      " Schema: _c0, blurb, state\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/randi/Documents/pyspark_udemy/Jupyter+Notebooks+and+Datasets+AS+of+16MAY21/Jupyter_Notebooks_and_Datasets_AS_of_16MAY21/Practice/Datasets/kickstarter.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/25 10:44:17 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , blurb, state\n",
      " Schema: _c0, blurb, state\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/randi/Documents/pyspark_udemy/Jupyter+Notebooks+and+Datasets+AS+of+16MAY21/Jupyter_Notebooks_and_Datasets_AS_of_16MAY21/Practice/Datasets/kickstarter.csv\n",
      "23/01/25 10:44:17 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , blurb, state\n",
      " Schema: _c0, blurb, state\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/randi/Documents/pyspark_udemy/Jupyter+Notebooks+and+Datasets+AS+of+16MAY21/Jupyter_Notebooks_and_Datasets_AS_of_16MAY21/Practice/Datasets/kickstarter.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/25 10:44:21 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , blurb, state\n",
      " Schema: _c0, blurb, state\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/randi/Documents/pyspark_udemy/Jupyter+Notebooks+and+Datasets+AS+of+16MAY21/Jupyter_Notebooks_and_Datasets_AS_of_16MAY21/Practice/Datasets/kickstarter.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/25 10:44:26 WARN DAGScheduler: Broadcasting large task binary with size 1287.8 KiB\n",
      "23/01/25 10:44:27 WARN DAGScheduler: Broadcasting large task binary with size 2.1 MiB\n",
      "23/01/25 10:44:28 WARN DAGScheduler: Broadcasting large task binary with size 1422.4 KiB\n",
      "23/01/25 10:44:28 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , blurb, state\n",
      " Schema: _c0, blurb, state\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/randi/Documents/pyspark_udemy/Jupyter+Notebooks+and+Datasets+AS+of+16MAY21/Jupyter_Notebooks_and_Datasets_AS_of_16MAY21/Practice/Datasets/kickstarter.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/25 10:44:32 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , blurb, state\n",
      " Schema: _c0, blurb, state\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/randi/Documents/pyspark_udemy/Jupyter+Notebooks+and+Datasets+AS+of+16MAY21/Jupyter_Notebooks_and_Datasets_AS_of_16MAY21/Practice/Datasets/kickstarter.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/25 10:44:36 WARN DAGScheduler: Broadcasting large task binary with size 1253.5 KiB\n",
      "23/01/25 10:44:37 WARN DAGScheduler: Broadcasting large task binary with size 2.1 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/25 10:44:38 WARN DAGScheduler: Broadcasting large task binary with size 1359.8 KiB\n",
      "23/01/25 10:44:38 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , blurb, state\n",
      " Schema: _c0, blurb, state\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/randi/Documents/pyspark_udemy/Jupyter+Notebooks+and+Datasets+AS+of+16MAY21/Jupyter_Notebooks_and_Datasets_AS_of_16MAY21/Practice/Datasets/kickstarter.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/25 10:44:39 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , blurb, state\n",
      " Schema: _c0, blurb, state\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/randi/Documents/pyspark_udemy/Jupyter+Notebooks+and+Datasets+AS+of+16MAY21/Jupyter_Notebooks_and_Datasets_AS_of_16MAY21/Practice/Datasets/kickstarter.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/25 10:44:41 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , blurb, state\n",
      " Schema: _c0, blurb, state\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/randi/Documents/pyspark_udemy/Jupyter+Notebooks+and+Datasets+AS+of+16MAY21/Jupyter_Notebooks_and_Datasets_AS_of_16MAY21/Practice/Datasets/kickstarter.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/25 10:44:43 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , blurb, state\n",
      " Schema: _c0, blurb, state\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/randi/Documents/pyspark_udemy/Jupyter+Notebooks+and+Datasets+AS+of+16MAY21/Jupyter_Notebooks_and_Datasets_AS_of_16MAY21/Practice/Datasets/kickstarter.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "\u001b[1mRandomForestClassifier  Feature Importances\u001b[0m\n",
      "(Scores add up to 1)\n",
      "Lowest score is the least important\n",
      " \n",
      "(3,[0,1,2],[0.38750004546505934,0.528986547761474,0.08351340677346668])\n",
      "23/01/25 10:44:46 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , blurb, state\n",
      " Schema: _c0, blurb, state\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/randi/Documents/pyspark_udemy/Jupyter+Notebooks+and+Datasets+AS+of+16MAY21/Jupyter_Notebooks_and_Datasets_AS_of_16MAY21/Practice/Datasets/kickstarter.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[Classifier: string, Result: string]"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = RandomForestClassifier()\n",
    "featureDF = W2VfeaturizedData\n",
    "\n",
    "train, test = featureDF.randomSplit([0.7, 0.3], seed=11)\n",
    "features = featureDF.select(['features']).collect()\n",
    "\n",
    "class_count = featureDF.select(countDistinct('label')).collect()\n",
    "classes = class_count[0] [0]\n",
    "\n",
    "ClassTrainEval(classifier, features, classes, train, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Failures:\n",
      "23/01/25 10:51:18 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , blurb, state\n",
      " Schema: _c0, blurb, state\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/randi/Documents/pyspark_udemy/Jupyter+Notebooks+and+Datasets+AS+of+16MAY21/Jupyter_Notebooks_and_Datasets_AS_of_16MAY21/Practice/Datasets/kickstarter.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------------------------------------------------------------------------------------------------------------------+\n",
      "|state |blurb                                                                                                                           |\n",
      "+------+--------------------------------------------------------------------------------------------------------------------------------+\n",
      "|failed|a san francisco based blog where artists from all over can come together to find inspiration as well as support each other      |\n",
      "|failed|aspiring canadian music producer and singersong writer who lives and loves music and art creating a debut alternative hip hop ep|\n",
      "|failed|everyday for the next days i will be creating a new digital portrait ive done so far the feedbacks been absolutely amazing      |\n",
      "+------+--------------------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 3 rows\n",
      "\n",
      " \n",
      "Predicted Success:\n",
      "23/01/25 10:51:22 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , blurb, state\n",
      " Schema: _c0, blurb, state\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/randi/Documents/pyspark_udemy/Jupyter+Notebooks+and+Datasets+AS+of+16MAY21/Jupyter_Notebooks_and_Datasets_AS_of_16MAY21/Practice/Datasets/kickstarter.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 16429:======>                                                (1 + 7) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------------------------------------------------------------------------------------------------------------------------------+\n",
      "|state |blurb                                                                                                                          |\n",
      "+------+-------------------------------------------------------------------------------------------------------------------------------+\n",
      "|failed| one pen stroke at a time                                                                                                      |\n",
      "|failed|a pilot program of five students focused on the interactions between ecology and humanity in the ceramic village of tamba japan|\n",
      "|failed|a public art studio embracing various fine arts and encouraging cultural crafts experienced students challenged art craft shows|\n",
      "+------+-------------------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "predictions = RF_BestModel.transform(test)\n",
    "print(\"Predicted Failures:\")\n",
    "predictions.select(\"state\",\"blurb\").filter(\"prediction=0\").orderBy(predictions[\"prediction\"].desc()).show(3,False)\n",
    "print(\" \")\n",
    "print(\"Predicted Success:\")\n",
    "predictions.select(\"state\",\"blurb\").filter(\"prediction=1\").orderBy(predictions[\"prediction\"].desc()).show(3,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyspark_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12 (main, Jun  1 2022, 11:38:51) \n[GCC 7.5.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "dfb866c31d58004e3cda695d24899844d76c112bfbb5c9450e4ceed919ae5341"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
